{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025-6-29 run it on \"python 3\" base env on ins-gl-pt-gpu24-2422a2a-gpuprof-3env-j4-1b with L4 GPU\n",
    "# on amlo-yieldoptim, generated new tar files with latents and caption emb, then train model with the new tar files\n",
    "\n",
    "# 2025-6-2 run it on \"python 3\" base env on ins-gl-pt-gpu24-2422a2a-gpuprof-3env-j4-1b with L4 GPU\n",
    "\n",
    "# 2025-5-20 run it on \"python 3\" base env on ins-gl-pt-gpu24-efe8b01-j4-0env-pdp with L4 GPU\n",
    "\n",
    "# ====================================\n",
    "# 2025-5-13 run it on \"python 3\" base env on ins-gl-pt-gpu24-2c94136-3env-j4-l4-test-1 with 1 L4 GPU\n",
    "# run on a single GPU notebook cell you can point the same script directly\n",
    "\n",
    "# steps of updating data to remvove mask channel:\n",
    "# 1. run this script (/Users/jinxuding/Downloads/CV/cubediff/implementation/llm-cv-pano-cubediff/cl/data/polyhaven/build_tiny_set.py) \n",
    "#   to generate the new data\n",
    "# 2. run this shell script (/Users/jinxuding/Downloads/CV/cubediff/implementation/llm-cv-pano-cubediff/cl/training/create_tar.sh) \n",
    "#   to create the tar file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d828dab-f0b4-4fd5-8f3b-2570f8bb260b",
   "metadata": {},
   "source": [
    "# download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"/home/jupyter/mluser/git/llm-cv-pano-cubediff\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/nvidia/lib64:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "# Set torch compile backend\n",
    "os.environ[\"TORCH_COMPILE_BACKEND\"] = \"inductor\"\n",
    "os.environ[\"ACCELERATE_CONFIG_FILE\"]=\"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/config/accelerate_config.yaml\"\n",
    "os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ebf5ff-ee54-43fe-9455-0ab4f9743dba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-20 16:51:40,044] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:cl.data.polyhaven.cubemap_builder:PyTorch GPU acceleration available: NVIDIA L4\n",
      "INFO:cl.data.polyhaven.cubemap_builder:Using 94 CPU cores for parallel processing\n",
      "INFO:cl.data.polyhaven.api_client:Fetching list of HDRIs from Polyhaven API (limit: 700)...\n",
      "ERROR:cl.data.polyhaven.api_client:Error accessing Polyhaven API: HTTPSConnectionPool(host='api.polyhaven.com', port=443): Max retries exceeded with url: /assets (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c88cca0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Using fallback HDRI list\n",
      "INFO:cl.data.polyhaven.api_client:Downloading 15 new HDRIs out of 15 total\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/wide_street_01_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/wide_street_01_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c88eb60>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/kloppenheim_06_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/kloppenheim_06_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c88f430>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/kloppenheim_02_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/kloppenheim_02_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c88fd00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/rural_asphalt_road_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/rural_asphalt_road_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d4610>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/wide_street_01_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d5000>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/wide_street_01.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/kloppenheim_06_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d5900>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/kloppenheim_06.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/kloppenheim_02_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d6230>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/kloppenheim_02.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/rural_asphalt_road_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d6b90>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/rural_asphalt_road.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/small_rural_road_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/small_rural_road_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d4a00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/abandoned_slaughterhouse_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/abandoned_slaughterhouse_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d73a0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/abandoned_tank_farm_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/abandoned_tank_farm_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d7b20>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/abandoned_factory_canteen_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/abandoned_factory_canteen_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb58704370>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/small_rural_road_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb58704c10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/small_rural_road.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/abandoned_slaughterhouse_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d6950>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/abandoned_slaughterhouse.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/abandoned_tank_farm_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d5e70>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/abandoned_tank_farm.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/abandoned_factory_canteen_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d5840>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/abandoned_factory_canteen.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/air_museum_entrance_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/air_museum_entrance_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb58705c00>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/aerodynamics_workshop_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/aerodynamics_workshop_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb587053f0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/alpine_cabin_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/alpine_cabin_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d65c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/alps_field_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/alps_field_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb58704a60>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/air_museum_entrance_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb587063e0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/air_museum_entrance.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/aerodynamics_workshop_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb58706b30>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/aerodynamics_workshop.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/alpine_cabin_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d52a0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/alpine_cabin.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error with alternative URL: HTTPSConnectionPool(host='dl.polyhaven.com', port=443): Max retries exceeded with url: /HDRIs/2k/exr/alps_field_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb5c8d5b70>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Created empty placeholder for /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp/alps_field.exr\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/autumn_forest_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/autumn_forest_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb587073a0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/artist_workshop_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/artist_workshop_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb58707bb0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "WARNING:cl.data.polyhaven.api_client:Error downloading https://dl.polyhaven.org/file/ph-assets/HDRIs/exr/2k/autumn_park_2k.exr: HTTPSConnectionPool(host='dl.polyhaven.org', port=443): Max retries exceeded with url: /file/ph-assets/HDRIs/exr/2k/autumn_park_2k.exr (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7dfb587303a0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "^C\n",
      "Process ForkProcess-31:\n",
      "Process ForkProcess-29:\n",
      "Process ForkProcess-22:\n",
      "Process ForkProcess-25:\n",
      "Process ForkProcess-24:\n",
      "Process ForkProcess-32:\n",
      "Process ForkProcess-30:\n",
      "Process ForkProcess-21:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-23:\n",
      "Process ForkProcess-27:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-26:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-2:\n",
      "Downloading HDRIs:  80%|███████████████████▏    | 12/15 [18:48<04:42, 94.07s/it]\n",
      "Process ForkProcess-28:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# 2025-5-20 copied data from \"merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/data\"\n",
    "# so no need to download and generate tar files.\n",
    "# # after installing packages\n",
    "# !python /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/polyhaven/build_tiny_set.py \\\n",
    "#       --out /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny \n",
    "#       --skip_download \\\n",
    "#       --skip_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f3ea6-dc31-4b21-b683-7d158f7a6213",
   "metadata": {},
   "source": [
    "# set up env "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac69ae2-8069-41e2-af78-82ac40ca85d4",
   "metadata": {},
   "source": [
    "# Step 1: build dataset from exr files (with testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79739d81-46a6-43cb-99ba-9042a5af4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo mount -o remount,size=64G /dev/shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2fcfed8-3210-4a08-bc81-f3d0ed7a5935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         193G   70G  124G  36% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "shm              64G     0   64G   0% /dev/shm\n",
      "/dev/nvme0n2    196G   29G  168G  15% /home/jupyter\n",
      "/dev/nvme0n1p1  193G   70G  124G  36% /usr/local/nvidia/bin\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dadb426-866c-4047-b750-fbe8a300f462",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-30 04:20:44,763 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:21<00:00,  3.01s/it]\n",
      "2025-06-30 04:21:14,014 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:21:14,829 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:21:15,029 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:21:15,106 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:21:15,118 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:21:15,121 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:21:15,199 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:21:15,208 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:21:15,224 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:21:15,240 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:21:15,255 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:21:15,279 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:32,001 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:32,213 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:32,392 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:32,514 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:32,574 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:32,685 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:32,821 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:32,828 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:32,889 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:32,943 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:33,025 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:33,056 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:33,096 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:33,112 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:33,182 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-30 04:27:33,214 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "\n",
      "real\t7m54.179s\n",
      "user\t111m58.960s\n",
      "sys\t8m5.171s\n"
     ]
    }
   ],
   "source": [
    "# 2025-6-14 build latent (.pt, shape [1, 6, 64, 64]), panorama, faces, captions (and embedding) and data validation report\n",
    "!time python /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/polyhaven/build_tiny_set.py \\\n",
    "    --exr_dir \"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp\" \\\n",
    "    --output_dir \"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny_13_new_pt\" \\\n",
    "    --cpu_workers 12 \\\n",
    "    --gpu_batch_size 64 \\\n",
    "    --split_ratio 0.9  > build_tiny_set_log_bs64_2025_6_29.txt\n",
    "\n",
    "# 2025-6-29 64 bs on 1 L4\n",
    "# real\t7m54.179s\n",
    "# user\t111m58.960s\n",
    "# sys\t8m5.171s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d07e0eb-c8b0-425e-bc95-0db3783a9697",
   "metadata": {},
   "source": [
    "# Step 2: Create WebDataset files (tar files for train and val) (with testing)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d27f595-d1c7-4774-bbde-09475b9e2e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    }
   ],
   "source": [
    "# !chmod +x create_tar.sh  \n",
    "!./create_tar.sh \\\n",
    "    --data_root /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny_13_new_pt \\\n",
    "    --workers 8 > create_tar_log_2025_6_29.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a403ecf-0307-4b61-ad87-1990a95a6bfe",
   "metadata": {},
   "source": [
    "# install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcdb6c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/simple\n",
      "Collecting torch==2.1.2\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/03/f1/13137340776dd5d5bcfd2574c9c6dfcc7618285035cd77240496e5c1a79b/torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Collecting torchvision==0.16.2\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/da/ae/76bd3682465730dea7be21f36a8160a911a470de6f26228904f222e7fefe/torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "Collecting peft>=0.8.2\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/68/85/8e6ea3d1089f2b6de3c1cd34bbbd7560912af9d34b057be3b8b8fefe1da3/peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Collecting opencv-python==4.8.1.78\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/b7/8a/b2f7e1a434d56bf1d7570fc5941ace0847404e1032d7f1f0b8fed896568d/opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "Collecting opencv-contrib-python==4.8.1.78\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/32/9e/4dcc0bb70e3b365dc85b8f96c63e6a306653f7cc6ed061aa6cc7b2bddee7/opencv_contrib_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.8 MB)\n",
      "Collecting matplotlib==3.8.2\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/19/e5/a4ea514515f270224435c69359abb7a3d152ed31b9ee3ba5e63017461945/matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Collecting tqdm==4.66.1\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Collecting einops==0.7.0\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "Collecting xformers\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/ff/e3/ee90c62a3235152d4ea8e983a5eb7ac00b10582fee86aaadb11571c1ecba/xformers-0.0.31-cp39-abi3-manylinux_2_28_x86_64.whl (117.1 MB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (11.1.0)\n",
      "Collecting openexr\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/2b/0c/7e913f31293194dfa45f7e6093017cacc3c75e2b8742027dfeced547daba/openexr-3.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting opencv-python-headless\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/dd/5c/c139a7876099916879609372bfa513b7f1257f7f1a908b0bdc1c2328241b/opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "Collecting wandb\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/88/c9/41b8bdb493e5eda32b502bc1cc49d539335a92cacaf0ef304d7dae0240aa/wandb-0.20.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.2 MB)\n",
      "Collecting bitsandbytes\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/72/27/ec6ee3408e09e01ab05db07af5a97dc76db7bc18824cf5f5dbc98e1e08a4/bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
      "Collecting webdataset\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/d9/00/aca6beb3658dab4ed3dbb41a78e6e7f31342e0b41d28088f205525751601/webdataset-1.0.2-py3-none-any.whl (74 kB)\n",
      "Collecting timm\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/3b/14/10d0ea58a7580b8bd7c8d69420b3dc3a1deb890d4ff297deca9717689598/timm-1.0.16-py3-none-any.whl (2.5 MB)\n",
      "Collecting diffusers\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/f8/e0/d5af850081d479e5bb6f6f310e98e1e2ea6cce9e5d67e2b7978d5690497e/diffusers-0.34.0-py3-none-any.whl (3.8 MB)\n",
      "Collecting huggingface_hub\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/d0/fb/5307bd3612eb0f0e62c3a916ae531d3a31e58fb5c82b58e3ebf7fd6f47a1/huggingface_hub-0.33.1-py3-none-any.whl (515 kB)\n",
      "Collecting accelerate\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/91/d9/e044c9d42d8ad9afa96533b46ecc9b7aea893d362b3c52bd78fb9fe4d7b3/accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
      "Collecting deepspeed\n",
      "  Using cached deepspeed-0.17.1-py3-none-any.whl\n",
      "Collecting imageio\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/cb/bd/b394387b598ed84d8d0fa90611a90bee0adc2021820ad5729f7ced74a8e2/imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (4.13.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/b6/9f/c64c03f49d6fbc56196664d05dba14e3a561038a81a638eeb47f4d4cfd48/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/eb/d5/c68b1d2cdfcc59e72e8a5949a37ddb22ae6cade80cd4a57a84d4c8b55472/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/7e/00/6b218edd739ecfc60524e585ba8e6b00554dd908de2c9c66c1af3e44e18d/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/44/31/4890b1c9abc496303412947fc7dcea3d14861720642b49e8ceed89636705/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/bc/1d/8de1e5c67099015c834315e333911273a8c6aaba78923dd1d1e25fc5f217/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/65/5b/cfaeebf25cd9fdec14338ccb16f6b2c4c7fa9163aefcf057d86b9cc248bb/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/a4/05/23f8f38eec3d28e4915725b233c24d8f1a33cb6540a882f7b54be1befa02/nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/da/d3/8057f0587683ed2fcd4dbfbdfdfa807b9160b809976099d36b8f60d08f03/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/4d/22/91a8af421c8a8902dde76e6ef3db01b258af16c53d81e8c0d0dc13900a9e/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.2) (1.25.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (2.9.0.post0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2) (12.4.99)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft>=0.8.2) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft>=0.8.2) (6.0.2)\n",
      "Collecting transformers (from peft>=0.8.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/5e/0c/68d03a38f6ab2ba2b2829eb11b334610dd236e7926787f7656001b68e1f2/transformers-4.53.0-py3-none-any.whl (10.8 MB)\n",
      "Collecting safetensors (from peft>=0.8.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/a6/f8/dae3421624fcc87a89d42e1898a798bc7ff72c61f38973a65d60df8f124c/safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting xformers\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/45/d0/4ed66b2d46bef4373f106b58361364cbd8ce53c85e60c8ea57ea254887bb/xformers-0.0.30-cp310-cp310-manylinux_2_28_x86_64.whl (31.5 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/55/4f/ef63f866ec7d3a23f78629604deaf379cd833fa4fd0cf7e6f8a77906f125/xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl (43.3 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/a1/44/7b27f60ec6f31f99cd5c2ee0553ab6c0bd7a289cc2abac076a859ddac143/xformers-0.0.29.post2-cp310-cp310-manylinux_2_28_x86_64.whl (44.3 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/28/1d/03356b31386a61162bccddf7fba6c792b4fe1159ad2af5f4b7879ce947ad/xformers-0.0.29.post1-cp310-cp310-manylinux_2_28_x86_64.whl (15.3 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/a4/63/cf772ebd81759ce93dbdbb6d0236092b8f570f90675d505dab2d560daab6/xformers-0.0.29-cp310-cp310-manylinux_2_28_x86_64.whl (15.3 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/02/56/d1a86f2c4a5a80e1f4926eef1ba69d6eb77ae823d36da7860984ca0b3421/xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/07/6c/62ce963a51e7c400f3720e93b479ce4020b8447b4d1e8138ec460e21b9d3/xformers-0.0.28.post2-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "INFO: pip is still looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/ca/24/3335df4d7c363188705be2808eb7e4bacfbfe23e3a4671c8f311236036d1/xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/7e/c9/a93741c2cc29dd44f361c801dd7e48f0d27617bf3951459578f20c61f511/xformers-0.0.28-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/04/69/f084d27545d130a960abb73fc84ad99f5260b3d98b55eef5dd065068055c/xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl (20.8 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/2b/20/2c00a2238e6b5cbad5ebc9cd6f60d6e5c28146a86fc02cfb9da3e14538db/xformers-0.0.27.post1-cp310-cp310-manylinux2014_x86_64.whl (20.8 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/3e/10/ce0d6e314b38ce8c438c04f5efc1498c8e68e4d9928cd5a2c046fc4f0923/xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl (164.1 MB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/32/e7/27003645ef99e7571fb6964cd2f39da3f1b3f3011aa00bb2d3ac9b790757/xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/5f/9b/f781a50d965717a2a2ea2c8d15e0f30deec8f9751a9874e850ba9ab0fadc/xformers-0.0.25.post1-cp310-cp310-manylinux2014_x86_64.whl (222.5 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/81/29/df65a2933a6a9acf19a90e0aef74b0bc69635bbe890204d5d03e7d89c85d/xformers-0.0.25-cp310-cp310-manylinux2014_x86_64.whl (222.5 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/78/c9/0cdbc2403666833302ab13f07b02b4556a5885b0542c7aa67f52d5ad0401/xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl (218.2 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/f4/89/ce8e936d3e64b3b565c16312dd6446d54f6e485f864130702c6b3b3cbe7c/xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.10.21)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/01/a1/fc4856bd02d2097324fb7ce05b3021fb850f864b83ca765f6e37e92ff8ca/sentry_sdk-2.32.0-py2.py3-none-any.whl (356 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/67/2b/c3cbd4a4462c1143465d8c151f1d51bbfb418e60a96a754329d28d416575/setproctitle-1.3.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "INFO: pip is looking at multiple versions of bitsandbytes to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting bitsandbytes\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/07/b7/cb5ce4d1a382cf53c19ef06c5fc29e85f5e129b4da6527dd207d90a5b8ad/bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "Collecting braceexpand (from webdataset)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/fa/93/e8c04e80e82391a6e51f218ca49720f64236bc824e92152a2633b74cf7ab/braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: importlib_metadata in /opt/conda/lib/python3.10/site-packages (from diffusers) (8.4.0)\n",
      "Collecting regex!=2019.12.17 (from diffusers)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/f2/98/26d3830875b53071f1f0ae6d547f1d98e964dd29ad35cbf94439120bb67a/regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/6d/2f/6cad7b5fe86b7652579346cb7f85156c11761df26435651cbba89376cd2c/hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Collecting hjson (from deepspeed)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/1f/7f/13cd798d180af4bf4c0ceddeefba2b864a63c71645abc0308b768d67bb81/hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from deepspeed) (1.1.0)\n",
      "Collecting ninja (from deepspeed)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/eb/7a/455d2877fe6cf99886849c7f9755d897df32eaf3a0fba47b56e615f880f7/ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Collecting py-cpuinfo (from deepspeed)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/e0/a9/023730ba63db1e494a271cb018dcd361bd2c917ba7004c3e49d5daf795a2/py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting pydantic<3 (from wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/6a/c0/ec2b1c8712ca690e5d61979dee872603e92b8a32f94cc1b72d53beab008a/pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Requirement already satisfied: nvidia-ml-py in /opt/conda/lib/python3.10/site-packages (from deepspeed) (11.495.46)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3->wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/31/0d/c8f7593e6bc7066289bbc366f2235701dcbebcd1ff0ef8e64f6f239fb47d/pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3->wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/17/69/cd203477f944c353c31bade965f880aa1061fd6bf05ded0726ca845b6ff7/typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.8.2) (1.17.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib_metadata->diffusers) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.2) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.2) (1.3.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers->peft>=0.8.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/c5/74/f41a432a0733f61f3d21b288de6dfa78f7acff309c6f0f323b2833e9189f/tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Installing collected packages: py-cpuinfo, hjson, braceexpand, webdataset, typing-inspection, triton, tqdm, setproctitle, sentry-sdk, safetensors, regex, pydantic-core, openexr, opencv-python-headless, opencv-python, opencv-contrib-python, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, imageio, hf-xet, einops, annotated-types, pydantic, nvidia-cusolver-cu12, nvidia-cudnn-cu12, matplotlib, huggingface_hub, wandb, torch, tokenizers, diffusers, xformers, transformers, torchvision, deepspeed, bitsandbytes, accelerate, timm, peft\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.0.0\n",
      "    Uninstalling triton-3.0.0:\n",
      "      Successfully uninstalled triton-3.0.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.99\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.99:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.99\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.3.0.142\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.0.142:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.0.142\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.5.119\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.119:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.119\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.0.44\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.0.44:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.0.44\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.99\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.99:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.99\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.99\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.99:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.99\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.99\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.99:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.99\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.4.2.65\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.2.65:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.2.65\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.21\n",
      "    Uninstalling pydantic-1.10.21:\n",
      "      Successfully uninstalled pydantic-1.10.21\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.0.99\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.0.99:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.0.99\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.3\n",
      "    Uninstalling matplotlib-3.7.3:\n",
      "      Successfully uninstalled matplotlib-3.7.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0+cu124\n",
      "    Uninstalling torch-2.4.0+cu124:\n",
      "      Successfully uninstalled torch-2.4.0+cu124\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.19.0+cu124\n",
      "    Uninstalling torchvision-0.19.0+cu124:\n",
      "      Successfully uninstalled torchvision-0.19.0+cu124\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dataproc-jupyter-plugin 0.1.80 requires pydantic~=1.10.0, but you have pydantic 2.11.7 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires matplotlib<=3.7.3,>=3.2, but you have matplotlib 3.8.2 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires pydantic<2,>=1.8.1, but you have pydantic 2.11.7 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.8.1 annotated-types-0.7.0 bitsandbytes-0.45.5 braceexpand-0.1.7 deepspeed-0.17.1 diffusers-0.34.0 einops-0.7.0 hf-xet-1.1.5 hjson-3.1.0 huggingface_hub-0.33.1 imageio-2.37.0 matplotlib-3.8.2 ninja-1.11.1.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 opencv-contrib-python-4.8.1.78 opencv-python-4.8.1.78 opencv-python-headless-4.11.0.86 openexr-3.3.4 peft-0.15.2 py-cpuinfo-9.0.0 pydantic-2.11.7 pydantic-core-2.33.2 regex-2024.11.6 safetensors-0.5.3 sentry-sdk-2.32.0 setproctitle-1.3.6 timm-1.0.16 tokenizers-0.21.2 torch-2.1.2 torchvision-0.16.2 tqdm-4.66.1 transformers-4.53.0 triton-2.1.0 typing-inspection-0.4.1 wandb-0.20.1 webdataset-1.0.2 xformers-0.0.23.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: torch-xla 2.4.0\n",
      "Uninstalling torch-xla-2.4.0:\n",
      "  Successfully uninstalled torch-xla-2.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.1.2 torchvision==0.16.2 \"peft>=0.8.2\" \\\n",
    "     opencv-python==4.8.1.78 opencv-contrib-python==4.8.1.78 matplotlib==3.8.2 tqdm==4.66.1 einops==0.7.0 \\\n",
    "     xformers requests pillow openexr opencv-python-headless wandb \\\n",
    "     bitsandbytes webdataset timm diffusers huggingface_hub accelerate deepspeed imageio \\\n",
    "     -i https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/simple\n",
    "\n",
    "!pip uninstall torch-xla -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d571efa-7e9b-49c2-8e8d-0087f7dd2876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate                               1.8.1\n",
      "diffusers                                0.34.0\n",
      "torch                                    2.1.2\n",
      "torchvision                              0.16.2\n",
      "transformers                             4.53.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep \"acc\\|torch\\|diff\\|trans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5183ad2-cc55-43cb-bd63-f8248d3bfe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import OpenEXR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5c9b47-6528-4d62-bdd9-8ab6d84b5528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: OpenEXR\n",
      "Version: 3.3.4\n",
      "Summary: Python bindings for the OpenEXR image file format\n",
      "Home-page: https://openexr.com\n",
      "Author: \n",
      "Author-email: Contributors to the OpenEXR project <info@openexr.com>\n",
      "License: \n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: numpy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show OpenEXR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912c226a-cc64-4866-b4bd-44b4fb1a7dcc",
   "metadata": {},
   "source": [
    "# create tar files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad8322a4-3b34-4bd3-a35c-c55c0fb24513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n",
      "\n",
      "real\t0m52.877s\n",
      "user\t0m45.080s\n",
      "sys\t0m40.177s\n"
     ]
    }
   ],
   "source": [
    "# !chmod +x create_tar.sh # \n",
    "!time ./create_tar.sh \\\n",
    "    --data_root /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny_13_new_pt \\\n",
    "    --workers 8 > create_tar_log_2025_6_29.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6707650-1bce-4be4-b97c-ba7347a997a3",
   "metadata": {},
   "source": [
    "# config shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c56498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate more memory for shm\n",
    "!sudo mount -o remount,size=64G /dev/shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8186ccc3-fcc2-4502-aba0-00981bc0d8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         193G   70G  124G  37% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "shm              64G   62M   64G   1% /dev/shm\n",
      "/dev/nvme0n2    196G   49G  148G  25% /home/jupyter\n",
      "/dev/nvme0n1p1  193G   70G  124G  37% /usr/local/nvidia/bin\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468e32c-6ee6-429a-8b84-45cf0470fc3d",
   "metadata": {},
   "source": [
    "# check models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e734c9a1-75e2-4d97-b3f9-dafb2e29bd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20K\n",
      "drwxr-xr-x 6 root root 4.0K Jun  1 06:00 models--openai--clip-vit-base-patch32\n",
      "drwxr-xr-x 6 root root 4.0K Jun 28 21:14 models--openai--clip-vit-large-patch14\n",
      "drwxr-xr-x 6 root root 4.0K Jun  1 06:00 models--runwayml--stable-diffusion-v1-5\n",
      "-rw-r--r-- 1 root root    1 Jun  1 06:00 version.txt\n",
      "-rw-r--r-- 1 root root    1 Jun  1 06:00 version_diffusers_cache.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/huggingface/hub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c50c239b-fa7e-441b-b5f7-63581e131d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 528M\n",
      "-rw-r--r-- 1 root root 528M Jun  1 06:04 vgg16-397923af.pth\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/torch/hub/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e39fe6-9d56-4755-a0b0-0a999f18a8d5",
   "metadata": {},
   "source": [
    "# run training\n",
    "### copied HF/hub and torch.hub from last VM to this VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a0b3de-be24-4ab5-af06-9ad9720cf324",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 2025-5-20 copied hf hub models to gcs and then copied them back to the target\n",
    "# gsutil -m cp -r \\\n",
    "#   ~/.cache/huggingface/hub \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/\n",
    "\n",
    "# on target VM:\n",
    "# mkdir -p ~/.cache/huggingface/hub\n",
    "# gsutil -m cp -r \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/* \\\n",
    "#   ~/.cache/huggingface/hub/\n",
    "\n",
    "# on source vm\n",
    "# copy torch/hub to the gcs and then to target vm\n",
    "# gsutil -m cp -r \\\n",
    "#   ~/.cache/torch/hub \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/torch_hub/\n",
    "\n",
    "# Copying file:///home/jupyter/.cache/torch/hub/checkpoints/vgg16-397923af.pth [Content-Type=application/octet-stream]...\n",
    "# ==> NOTE: You are uploading one or more large file(s), which would run          \n",
    "# significantly faster if you enable parallel composite uploads. This\n",
    "# feature can be enabled by editing the\n",
    "# \"parallel_composite_upload_threshold\" value in your .boto\n",
    "# configuration file. However, note that if you do this large files will\n",
    "# be uploaded as `composite objects\n",
    "# <https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
    "# means that any user who downloads such objects will need to have a\n",
    "# compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
    "# without a compiled crcmod, computing checksums on composite objects is\n",
    "# so slow that gsutil disables downloads of composite objects.\n",
    "\n",
    "# | [1/1 files][527.8 MiB/527.8 MiB] 100% Done                                    \n",
    "# Operation completed over 1 objects/527.8 MiB.  \n",
    "\n",
    "# on target VM:\n",
    "# mkdir -p ~/.cache/torch/hub\n",
    "# gsutil -m cp -r \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/torch_hub/hub/* \\\n",
    "#   ~/.cache/torch/hub/\n",
    "\n",
    "# Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/torch_hub/hub/checkpoints/vgg16-397923af.pth...\n",
    "# - [1/1 files][527.8 MiB/527.8 MiB] 100% Done                                    \n",
    "# Operation completed over 1 objects/527.8 MiB.             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "716bf35b-8d9a-40b9-9c8b-e5885d854e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025-5-20 after copying the models, this should work well.\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "# MAX_LEN  = tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29bc6b6b-fda4-40a7-8bbe-46d80b17f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8545d-310f-4e2f-8204-ef3df3f2d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"/home/jupyter/mluser/git/llm-cv-pano-cubediff\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/nvidia/lib64:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "# Set torch compile backend\n",
    "os.environ[\"TORCH_COMPILE_BACKEND\"] = \"inductor\"\n",
    "os.environ[\"ACCELERATE_CONFIG_FILE\"]=\"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/config/accelerate_config.yaml\"\n",
    "# If set this before importing torch, DeepSpeed’s internal calls to torch.save will automatically use the old writer (no extra temp copy),\n",
    "# this can save deepspeed checkpoints memory usage and speed up training.\n",
    "os.environ[\"TORCH_USE_NEW_ZIPFILE_SERIALIZATION\"] = \"0\"\n",
    "os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ddf3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCELERATE_CONFIG_FILE=\"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/config/accelerate_config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56703ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.18it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.32it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.25it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.23it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.23it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.24it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.23it/s]\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.18it/s]\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --config_file $ACCELERATE_CONFIG_FILE train_cubediff.py --cfg ../config/tiny_fullrank.yaml > cubediff_log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204768e5-1625-4a2c-a967-01ca58cf7b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
