{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda50da-b3b9-417d-a342-daa77f0a7db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025-10-29 run it in \"pytohn 3\" env on pytorch-cc-nba3-wbi of bbyus-trn-amlo-yieldoptimz-p01\n",
    "# to download openai/clip-vit-base-patch32 and copied it to gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub1/models--openai--clip-vit-base-patch32\n",
    "# used it to replace \"gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32\" that couldn't be loaded na matter \"local_files_only=True or False\".\n",
    "# and \"use_safetensors=True or False\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9160fe-0d14-42b7-90f9-f57b2688f3b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.57.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.0 (from torch)\n",
      "  Downloading triton-3.5.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2025.7.14)\n",
      "Downloading torch-2.9.0-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m969.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.3/170.3 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/19\u001b[0m [torch]m18/19\u001b[0m [torch]-cusolver-cu12]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed mpmath-1.3.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.9.0 triton-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea30b5b9-8696-4c33-b3d3-5c2f8826efff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000bbcf66a9b493aba23551b019df9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c096b539a5b419588b7c5d25f184123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595ebf12634f46949559580c209129ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb7cb01da6f4f278b220d8b3a8f1a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e066276e834d4ca2ab90b16851b075fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dcd1f7d3834d4cb3895e6c41af2763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cff4d333d224e51878e52ecad5d5440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b0be106e134588809b9dfc02aef074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d5356d2501455e8c131a86ae9dc0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import CLIPModel, CLIPProcessor\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "model.save_pretrained(\"./clip-vit-base-patch32\")\n",
    "processor.save_pretrained(\"./clip-vit-base-patch32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c557c4-7a54-4dba-a250-8ca012c2ac04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import CLIPModel, CLIPProcessor\n",
    "\n",
    "# This should now work without network calls\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\", use_safetensors=True, local_files_only=True)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "005506ee-2689-4201-8f0e-17ed5b2bc1d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./clip-vit-base-patch32/config.json [Content-Type=application/json]...\n",
      "Copying file://./clip-vit-base-patch32/merges.txt [Content-Type=text/plain]...\n",
      "Copying file://./clip-vit-base-patch32/model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file://./clip-vit-base-patch32/preprocessor_config.json [Content-Type=application/json]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://./clip-vit-base-patch32/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./clip-vit-base-patch32/tokenizer.json [Content-Type=application/json]...\n",
      "Copying file://./clip-vit-base-patch32/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./clip-vit-base-patch32/vocab.json [Content-Type=application/json]...\n",
      "\\ [8/8 files][581.9 MiB/581.9 MiB] 100% Done                                    \n",
      "Operation completed over 8 objects/581.9 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r ./clip-vit-base-patch32/*.* gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/clip-vit-base-patch32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45dbcc75-6db5-4706-bcf8-eba9829f5051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12K\n",
      "drwxr-xr-x 2 jupyter jupyter 4.0K Oct 29 11:05 blobs\n",
      "drwxr-xr-x 3 jupyter jupyter 4.0K Oct 29 11:05 refs\n",
      "drwxr-xr-x 4 jupyter jupyter 4.0K Oct 29 11:05 snapshots\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7eb88f1-c37b-48bd-a823-03f22a3a43f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/blobs/182766ce89b439768edadda342519f33802f5364 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/blobs/a63082132ba4f97a80bea76823f544493bffa8082296d62d71581a4feff1576f [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/blobs/5a12a1eb250987a4eee0e3e7d7338c4b22724be1 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/blobs/564c0ebd5ce29c4ee4864004aee693deadd3128c [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/blobs/4fdaf6842dd5a725b940c92b6b692490ce59d548 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/blobs/9bfb42aa97dcd61e89f279ccaee988bccb4fabae [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/blobs/a2a88b96561196777ca173b15309ea859f4d2ce0 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/blobs/99d28a652e6ec46629ab7047a0ac82c69b1fe11e0ce672c43af65d3a9a3fc05d [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/blobs/bbfec752c9a675946c6dce106def6f35c882dcc2 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/refs/main [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/refs/refs/pr/66 [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/c237dc49a33fc61debc9276459120b7eac67e7ef/model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/vocab.json [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/config.json [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/merges.txt [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/tokenizer.json [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/preprocessor_config.json [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/pytorch_model.bin [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/tokenizer_config.json [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/special_tokens_map.json [Content-Type=application/octet-stream]...\n",
      "| [20/20 files][  2.3 GiB/  2.3 GiB] 100% Done                                  \n",
      "Operation completed over 20 objects/2.3 GiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r /home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/*  gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub1/models--openai--clip-vit-base-patch32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8591afdf-f7ca-4c65-8b3a-cb897aa89ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025-11-27 run it from \"python 3\" env in gl-base-env-j4-ces with 1 L4 gpu\n",
    "# copied from \n",
    "#    gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/clip-vit-base-patch32\n",
    "# to\n",
    "#    gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268\n",
    "# in order to load vit model with safe_tensors\n",
    "# because \"3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268\" was missing some files (at leaset two files).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39de934b-99e3-4a50-99c2-36ae847f5e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/config.json#1747765747270032...\n",
      "Removing gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/merges.txt#1747765746969025...\n",
      "Removing gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/special_tokens_map.json#1747765747429945...\n",
      "Removing gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/tokenizer.json#1747765747837133...\n",
      "/ [4 objects]                                                                   \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m rm ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Removing gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/tokenizer_config.json#1747765747339865...\n",
      "Removing gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/vocab.json#1747765747255209...\n",
      "/ [6 objects]                                                                   \n",
      "Operation completed over 6 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "!gsutil rm -rf gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c03b0fec-14d2-490f-b62f-be9aee6bb111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/clip-vit-base-patch32/config.json [Content-Type=application/json]...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/clip-vit-base-patch32/merges.txt [Content-Type=text/plain]...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/clip-vit-base-patch32/model.safetensors [Content-Type=application/octet-stream]...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/clip-vit-base-patch32/preprocessor_config.json [Content-Type=application/json]...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/clip-vit-base-patch32/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/clip-vit-base-patch32/tokenizer.json [Content-Type=application/json]...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/clip-vit-base-patch32/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/clip-vit-base-patch32/vocab.json [Content-Type=application/json]...\n",
      "/ [8/9 files][581.9 MiB/581.9 MiB]  99% Done                                    "
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/clip-vit-base-patch32/* gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c582cc70-f891-4cd0-b256-9a8eb7376339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 581M\n",
      "-rw-r--r-- 1 jupyter jupyter 4.1K Nov 18 00:03 config.json\n",
      "-rw-r--r-- 1 jupyter jupyter 513K Nov 18 00:03 merges.txt\n",
      "-rw-r--r-- 1 jupyter jupyter  316 Nov 18 00:03 preprocessor_config.json\n",
      "-rw-r--r-- 1 jupyter jupyter 578M Nov 18 00:03 pytorch_model.bin\n",
      "-rw-r--r-- 1 jupyter jupyter  389 Nov 18 00:03 special_tokens_map.json\n",
      "-rw-r--r-- 1 jupyter jupyter 2.2M Nov 18 00:03 tokenizer.json\n",
      "-rw-r--r-- 1 jupyter jupyter  592 Nov 18 00:03 tokenizer_config.json\n",
      "-rw-r--r-- 1 jupyter jupyter 843K Nov 18 00:03 vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls  -lh ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf26fff-2a6d-4128-a962-34f008439297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the current 3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268\n",
    "!rm -rf ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "727fb4d2-9043-4604-8b63-84d9cc66fe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls  -lh ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1956dbac-6a47-4fdb-a500-85ed8f49a9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/config.json...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/merges.txt...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/model.safetensors...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/preprocessor_config.json...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/special_tokens_map.json...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/tokenizer.json...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/tokenizer_config.json...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/vocab.json...\n",
      "| [8/8 files][581.9 MiB/581.9 MiB] 100% Done                                    \n",
      "Operation completed over 8 objects/581.9 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# copy the new vit model with safe_tensors to hf cache\n",
    "!gsutil -m cp -r gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/ ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d06026b4-2914-47a2-a9a4-2363f35cbe32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 582M\n",
      "-rw-r--r-- 1 jupyter jupyter 1.2K Nov 18 20:55 config.json\n",
      "-rw-r--r-- 1 jupyter jupyter 513K Nov 18 20:55 merges.txt\n",
      "-rw-r--r-- 1 jupyter jupyter 578M Nov 18 20:55 model.safetensors\n",
      "-rw-r--r-- 1 jupyter jupyter  504 Nov 18 20:55 preprocessor_config.json\n",
      "-rw-r--r-- 1 jupyter jupyter  588 Nov 18 20:55 special_tokens_map.json\n",
      "-rw-r--r-- 1 jupyter jupyter 3.5M Nov 18 20:55 tokenizer.json\n",
      "-rw-r--r-- 1 jupyter jupyter  774 Nov 18 20:55 tokenizer_config.json\n",
      "-rw-r--r-- 1 jupyter jupyter 843K Nov 18 20:55 vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls  -lh ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef6aabb-9702-4d23-ab44-dc97f7107205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b319c0c0-4906-4206-b66c-31858f2cc871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPModel, CLIPProcessor\n",
    "\n",
    "# This should now work without network calls\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\", use_safetensors=True, local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dd32948-888a-47a9-902d-63bdb01242d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'openai/clip-vit-base-patch32'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ee139a0-695e-467d-814b-13a1b3708e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ok\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268/tokenizer.json\") as f:\n",
    "    json.load(f)\n",
    "    print(\"load ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ad2986e-00b6-47a2-831c-deed4ca93143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.35.2\n",
      "0.15.2\n"
     ]
    }
   ],
   "source": [
    "import transformers, tokenizers\n",
    "\n",
    "print(transformers.__version__)\n",
    "print(tokenizers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75302ce0-fda5-4516-9f2e-11e990188969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025-11-18\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\", use_safetensors=True, local_files_only=True, use_fast=False) # -> worked\n",
    "# processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\", use_safetensors=True, local_files_only=True) -> failed due to transformers 4.35.2 was new and used fast tokenizer expects new schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f94039c-11f4-430d-878c-21e993b26e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16d118-4dfc-419d-b5bc-1568503f15c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
