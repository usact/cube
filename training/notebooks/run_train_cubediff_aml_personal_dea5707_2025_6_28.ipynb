{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025-7-7 optimize training time (~2.2 seconds per weight-update stepn on 4L4 GPU)\n",
    "# 2025-6-28 run it on \"python 3\" base env on ins-gl-pt-gpu24-dea5707-gpuprof-3env-j4-1b with L4/A100 GPU\n",
    "# on personal, generated new tar files with latents and caption emb, then train model with the new tar files\n",
    "\n",
    "# 2025-6-12 run it on \"python 3\" base env on ins-gl-pt-gpu24-dea5707-gpuprof-3env-j4-1b with L4/A100 GPU\n",
    "# on personal test new tar files with latents and caption emb\n",
    "\n",
    "# 2025-5-31 run it on \"python 3\" base env on ins-gl-pt-gpu24-2422a2a-gpuprof-3env-j4-1b with L4/A100 GPU\n",
    "# on yieldoptimz\n",
    "# ====================================\n",
    "# 2025-5-13 run it on \"python 3\" base env on ins-gl-pt-gpu24-2c94136-3env-j4-l4-test-1 with 1 L4 GPU\n",
    "# run on a single GPU notebook cell you can point the same script directly\n",
    "\n",
    "# steps of updating data to remvove mask channel:\n",
    "# 1. run this script (/Users/jinxuding/Downloads/CV/cubediff/implementation/llm-cv-pano-cubediff/cl/data/polyhaven/build_tiny_set.py) \n",
    "#   to generate the new data\n",
    "# 2. run this shell script (/Users/jinxuding/Downloads/CV/cubediff/implementation/llm-cv-pano-cubediff/cl/training/create_tar.sh) \n",
    "#   to create the tar file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d828dab-f0b4-4fd5-8f3b-2570f8bb260b",
   "metadata": {},
   "source": [
    "# download and process data (exr -> latents, captions, panoramas, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"/home/jupyter/mluser/git/llm-cv-pano-cubediff\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/nvidia/lib64:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "# Set torch compile backend\n",
    "os.environ[\"TORCH_COMPILE_BACKEND\"] = \"inductor\"\n",
    "os.environ[\"ACCELERATE_CONFIG_FILE\"]=\"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/config/accelerate_config.yaml\"\n",
    "os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ebf5ff-ee54-43fe-9455-0ab4f9743dba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 2025-5-20 copied data from \"merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/data\"\n",
    "# so no need to download and generate tar files.\n",
    "# # after installing packages\n",
    "# !python /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/polyhaven/build_tiny_set.py \\\n",
    "#       --out /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny \n",
    "#       --skip_download \\\n",
    "#       --skip_convert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f3ea6-dc31-4b21-b683-7d158f7a6213",
   "metadata": {},
   "source": [
    "# set up env "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb7dfb-2185-49f8-b75a-7205d15ede23",
   "metadata": {},
   "source": [
    "# Step 1: build dataset from exr files (with testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf14a0a-27a8-4e9d-aa14-4ebd1c2eb085",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo mount -o remount,size=64G /dev/shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2edcbaee-ba4d-4855-8f6f-edb1b34bdeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         193G   66G  128G  34% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "shm              64G     0   64G   0% /dev/shm\n",
      "/dev/nvme0n2    196G  128G   69G  65% /home/jupyter\n",
      "/dev/nvme0n1p1  193G   66G  128G  34% /usr/local/nvidia/bin\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d53cb5-9ff0-47b8-9e9a-59d19da7a1d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-16 20:13:25,666 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  6.25it/s]\n",
      "2025-06-16 20:13:34,280 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:13:34,329 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:13:34,383 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:13:34,384 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:13:34,406 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:13:34,425 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:13:34,428 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:13:34,434 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:13:34,434 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:13:34,439 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:13:34,439 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:13:34,443 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:56,101 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:56,124 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:56,139 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:56,152 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:56,397 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:56,425 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:56,439 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:56,447 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:56,483 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:56,485 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:56,503 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:56,589 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:56,833 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:57,086 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:57,401 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "2025-06-16 20:19:57,533 - INFO - PyTorch GPU acceleration available: NVIDIA L4\n",
      "\n",
      "real\t7m37.145s\n",
      "user\t73m17.991s\n",
      "sys\t3m10.641s\n"
     ]
    }
   ],
   "source": [
    "# 2025-6-14 build latent (.pt, shape [1, 6, 64, 64]), panorama, faces, captions (and embedding) and data validation report\n",
    "# !time python /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/polyhaven/build_tiny_set.py \\\n",
    "#     --exr_dir \"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp\" \\\n",
    "#     --output_dir \"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny_13_new_pt\" \\\n",
    "#     --cpu_workers 12 \\\n",
    "#     --gpu_batch_size 64 \\\n",
    "#     --split_ratio 0.9  > build_tiny_set_log_bs64_2025_6_16.txt\n",
    "\n",
    "# 2025-6-15\n",
    "# 7 min for 64 bach size\n",
    "# 128 batch size\n",
    "# real\t5m15.717s\n",
    "# user\t84m56.800s\n",
    "# sys\t2m42.700s\n",
    "\n",
    "# 256 batch size\n",
    "# real\t5m12.965s\n",
    "# user\t85m53.138s\n",
    "# sys\t2m44.637s\n",
    "\n",
    "# 2025-6-16\n",
    "# 256 batch size OOM\n",
    "# real\t6m5.894s\n",
    "# user\t79m58.162s\n",
    "# sys\t3m13.432s\n",
    "\n",
    "# 2025-6-16\n",
    "# 256 batch size OOM\n",
    "# real\t5m43.930s\n",
    "# user\t81m7.982s\n",
    "# sys\t3m3.158s\n",
    "\n",
    "# 128 bs OOM\n",
    "\n",
    "# 2025-6-16\n",
    "# 64 batch size \n",
    "# real\t8m11.073s\n",
    "# user\t71m29.201s\n",
    "# sys\t3m12.924s\n",
    "\n",
    "# 64 batch size build_tiny_set_log_bs64_2025_6_16.txt\n",
    "# real\t7m37.145s\n",
    "# user\t73m17.991s\n",
    "# sys\t3m10.641s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a868afa4-db69-4cdb-86e2-bb14b335d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2025-6-8 build .pt, panorama, faces, captions\n",
    "# !python  /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/polyhaven/build_tiny_set.py \\\n",
    "#     --exr_dir    \"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny/raw/erp\" \\\n",
    "#     --output_dir \"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny_13_new_pt\" \\\n",
    "#     --split_ratio 0.90 \\\n",
    "#     --seed        42 \\\n",
    "#     --workers     8 \\\n",
    "#     --test_faces \\\n",
    "#     --validate \\\n",
    "#     --batch_encode \n",
    "\n",
    "# > build_tiny_set_log.txt\n",
    "\n",
    "#     # --test_faces  # validate the generated cubemap faces have correct orientations.\n",
    "#     # --validate    # Comprehensive validation of the generated dataset structure and content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65979da-08b4-4259-8707-74fbb4952bb4",
   "metadata": {},
   "source": [
    "# Step 2: Create WebDataset files (with testing)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7146c40c-ccb1-41c1-a8e8-a92400b741b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (308674745.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    ./create_tar.sh          # Generates helper scripts\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ./create_tar.sh          # Generates helper scripts and call \"process_cubediff_data.sh\" automatically.\n",
    "# ./process_cubediff_data.sh  # Creates TAR files + runs tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "419c36af-5bf5-4008-8a6c-5abb22a7c68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:379: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\"WebDataset(shardshuffle=...) is None; set explicitly to False or a number\")\n"
     ]
    }
   ],
   "source": [
    "# !chmod +x create_tar.sh # \n",
    "!./create_tar.sh \\\n",
    "    --data_root /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny_13_new_pt \\\n",
    "    --workers 8 > create_tar_log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6846f9a-a8e8-4b0e-af9f-b5b974bfc32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output: mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny_8_new_pt\n",
    "# Run all tests\n",
    "python cl.data.latent_webdataset.py --tar cl.data.dataspace.polyhaven_tiny_8_new_pt.cubediff_train.tar --test all\n",
    "\n",
    "# # Test only dataloader\n",
    "# python latent_webdataset.py --tar cubediff_train.tar --test dataloader --batch_size 4\n",
    "\n",
    "# Debug sample structure  \n",
    "python cl.data.latent_webdataset.py --tar cl.data.dataspace.polyhaven_tiny_8_new_pt.cubediff_train.tar --test debug --num_samples 10\n",
    "\n",
    "# # Create visualizations\n",
    "# python latent_webdataset.py --tar cubediff_train.tar --test visualization --num_samples 5\n",
    "\n",
    "# Benchmark performance\n",
    "python cl.data.latent_webdataset.py --tar cl.data.dataspace.polyhaven_tiny_8_new_pt.cubediff_train.tar --test benchmark --batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24844b72-9bcf-4f81-b9fc-e837937f813c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.97s/it]\n",
      "âœ… Loaded runwayml/stable-diffusion-v1-5 from cache\n",
      "================================================================================\n",
      "ðŸ§ª LATENT WEBDATASET TESTING SUITE\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£ DATALOADER TEST\n",
      "----------------------------------------\n",
      "ðŸ§ª Testing dataloader with /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny_11_new_pt/cubediff_train.tar\n",
      "[latent_webdataset] rank 0 â€“ is_eval=True â€“ materializing WebDataset pipeline...\n",
      "[latent_webdataset] rank 0 â€“ is_eval=True â€“ full mapped pipeline length = 630 (expected ~100)\n",
      "[latent_webdataset] rank 0 â€“ taking slice [0:630] = 630 samples from 630 total\n",
      "[latent_webdataset] rank 0 â€“ DataLoader ready: 630 samples, batch_size=2, ~315 batches\n",
      "ðŸ“Š DataLoader created with 315 batches\n",
      "\n",
      "Batch 1:\n",
      "  Latent shape: torch.Size([2, 6, 4, 64, 64])\n",
      "  Encoder hidden states shape: torch.Size([2, 77, 768])\n",
      "  Attention mask shape: torch.Size([2, 77])\n",
      "  Latent resolution: 64Ã—64 âœ… CORRECT\n",
      "  Latent value range: [-10.117, 6.551]\n",
      "\n",
      "Batch 2:\n",
      "  Latent shape: torch.Size([2, 6, 4, 64, 64])\n",
      "  Encoder hidden states shape: torch.Size([2, 77, 768])\n",
      "  Attention mask shape: torch.Size([2, 77])\n",
      "  Latent resolution: 64Ã—64 âœ… CORRECT\n",
      "  Latent value range: [-9.688, 9.492]\n",
      "\n",
      "Batch 3:\n",
      "  Latent shape: torch.Size([2, 6, 4, 64, 64])\n",
      "  Encoder hidden states shape: torch.Size([2, 77, 768])\n",
      "  Attention mask shape: torch.Size([2, 77])\n",
      "  Latent resolution: 64Ã—64 âœ… CORRECT\n",
      "  Latent value range: [-9.797, 10.312]\n",
      "\n",
      "âœ… DataLoader test completed\n",
      "\n",
      "2ï¸âƒ£ SAMPLE STRUCTURE DEBUG\n",
      "----------------------------------------\n",
      "ðŸ” Debugging sample structure in /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny_11_new_pt/cubediff_train.tar\n",
      "/opt/conda/lib/python3.10/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\n",
      "\n",
      "Sample 0: abandoned_church\n",
      "  Keys: ['__key__', '__url__', 'abandoned_church.npz', '__local_path__', 'abandoned_church.pt', 'abandoned_church.txt']\n",
      "  .pt files: 1\n",
      "  .txt files: 1\n",
      "  Latent shape: torch.Size([6, 4, 64, 64])\n",
      "  Latent dtype: torch.float16\n",
      "  Latent range: [-7.395, 6.551]\n",
      "  Caption: 'abandoned church'\n",
      "\n",
      "Sample 1: abandoned_construction\n",
      "  Keys: ['__key__', '__url__', 'abandoned_construction.npz', '__local_path__', 'abandoned_construction.pt', 'abandoned_construction.txt']\n",
      "  .pt files: 1\n",
      "  .txt files: 1\n",
      "  Latent shape: torch.Size([6, 4, 64, 64])\n",
      "  Latent dtype: torch.float16\n",
      "  Latent range: [-10.117, 5.766]\n",
      "  Caption: 'abandoned construction'\n",
      "\n",
      "ðŸ“Š Summary:\n",
      "  Samples examined: 2\n",
      "  Latent shapes found: {'(6, 4, 64, 64)': 2}\n",
      "\n",
      "3ï¸âƒ£ LATENT VISUALIZATION TEST\n",
      "----------------------------------------\n",
      "ðŸŽ¨ Testing latent visualization with /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny_11_new_pt/cubediff_train.tar\n",
      "Sample 0: abandoned_church\n",
      "  Latent shape: torch.Size([6, 4, 64, 64])\n",
      "/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/latent_webdataset.py:320: UserWarning: Glyph 9989 (\\N{WHITE HEAVY CHECK MARK}) missing from current font.\n",
      "  plt.tight_layout()\n",
      "/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/latent_webdataset.py:323: UserWarning: Glyph 9989 (\\N{WHITE HEAVY CHECK MARK}) missing from current font.\n",
      "  plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
      "Saved visualization: test_outputs/latent_visualizations/abandoned_church_latent_faces.png\n",
      "Sample 1: abandoned_construction\n",
      "  Latent shape: torch.Size([6, 4, 64, 64])\n",
      "Saved visualization: test_outputs/latent_visualizations/abandoned_construction_latent_faces.png\n",
      "\n",
      "âœ… Created 2 latent visualizations in test_outputs/latent_visualizations\n",
      "\n",
      "4ï¸âƒ£ DATALOADER BENCHMARK\n",
      "----------------------------------------\n",
      "âš¡ Benchmarking dataloader with /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny_11_new_pt/cubediff_train.tar\n",
      "   Batch size: 2, Batches to test: 10\n",
      "[latent_webdataset] rank 0 â€“ is_eval=True â€“ materializing WebDataset pipeline...\n",
      "[latent_webdataset] rank 0 â€“ is_eval=True â€“ full mapped pipeline length = 630 (expected ~1000)\n",
      "[latent_webdataset] rank 0 â€“ taking slice [0:630] = 630 samples from 630 total\n",
      "[latent_webdataset] rank 0 â€“ DataLoader ready: 630 samples, batch_size=2, ~315 batches\n",
      "ðŸ“Š DataLoader created with 315 total batches\n",
      "ðŸ”¥ Warming up...\n",
      "   Warm-up batch shape: torch.Size([2, 6, 4, 64, 64])\n",
      "â±ï¸  Benchmarking...\n",
      "   Batch 0: 0.001s, latent shape: torch.Size([2, 6, 4, 64, 64])\n",
      "   Batch 1: 0.000s, latent shape: torch.Size([2, 6, 4, 64, 64])\n",
      "   Batch 2: 0.000s, latent shape: torch.Size([2, 6, 4, 64, 64])\n",
      "\n",
      "ðŸ“ˆ Benchmark Results:\n",
      "   Total time: 0.283s\n",
      "   Average batch time: 0.000s\n",
      "   Batches per second: 2543.24\n",
      "   Samples per second: 5086.47\n",
      "\n",
      "âœ… All tests completed!\n"
     ]
    }
   ],
   "source": [
    "!python /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/latent_webdataset.py --tar /home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny_11_new_pt/cubediff_train.tar --test all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bbc6f6-c1fa-4c45-8350-559f25a850fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80ab6261-8973-446b-a73f-35a6270d5872",
   "metadata": {},
   "source": [
    "# generate py files that will be used to create train and val tar files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5a60c-e4df-4c17-a175-e0f5654dadb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025-5-14 generate py files that will be used to create train and val tar files\n",
    "# run \"create_tar.sh\" to generate :\n",
    "# make_train_val_tars.py\n",
    "# verify_simple.py\n",
    "# load_webdataset.py\n",
    "# process_cubediff_data.sh\n",
    "\n",
    "# root@af45057ae158:~/mluser/git/llm-cv-pano-cubediff/cl/training# ./create_tar.sh \n",
    "# ===== Fixing WebDataset Issues for CubeDiff Data =====\n",
    "# ===== Setup Complete =====\n",
    "# To process your CubeDiff data, run:\n",
    "#   ./process_cubediff_data.sh\n",
    "\n",
    "# This script will:\n",
    "# 1. Create the WebDataset tar files with proper formatting\n",
    "# 2. Verify the structure of the tar files\n",
    "# 3. Load the data and create visualizations\n",
    "\n",
    "# The key fix is using standard WebDataset naming conventions\n",
    "# for the files within the tar, which resolves the AssertionError.\n",
    "# root@af45057ae158:~/mluser/git/llm-cv-pano-cubediff/cl/training# ls -lh *.sh\n",
    "# -rwxr-xr-x 1 root root  19K Apr 26 17:02 create_tar.sh\n",
    "# -rwxr-xr-x 1 root root 2.4K May 15 05:15 process_cubediff_data.sh\n",
    "# -rwxr-xr-x 1 root root  581 Apr 28 06:47 run_train.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d07e0eb-c8b0-425e-bc95-0db3783a9697",
   "metadata": {},
   "source": [
    "# generate tar files for train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c380b0-7c5e-4ff9-9030-149e351e7f60",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 2025-5-14\n",
    "# root@af45057ae158:~/mluser/git/llm-cv-pano-cubediff/cl/training# ./process_cubediff_data.sh\n",
    "# =====================================\n",
    "# CubeDiff Data Processing Pipeline\n",
    "# =====================================\n",
    "# Data locations:\n",
    "# - Latents: ../data/dataspace/polyhaven_tiny/latents\n",
    "# - Captions: ../data/dataspace/polyhaven_tiny/raw/captions.json\n",
    "# - Output train tar: ../data/dataspace/polyhaven_tiny/cubediff_train.tar\n",
    "# - Output val tar: ../data/dataspace/polyhaven_tiny/cubediff_val.tar\n",
    "# - Validation fraction: 0.071\n",
    "# =====================================\n",
    "\n",
    "\n",
    "# ===== STEP 1: Creating WebDataset tar files =====\n",
    "# Loaded 700 captions\n",
    "# First 3 caption keys: ['abandoned_bakery', 'abandoned_church', 'abandoned_construction']\n",
    "# Found 700 latent files\n",
    "# First 3 latent files: ['../data/dataspace/polyhaven_tiny/latents/abandoned_bakery.pt', '../data/dataspace/polyhaven_tiny/latents/abandoned_church.pt', '../data/dataspace/polyhaven_tiny/latents/abandoned_construction.pt']\n",
    "# Extracted 700 IDs\n",
    "# First 3 IDs: ['abandoned_bakery', 'abandoned_church', 'abandoned_construction']\n",
    "# ID abandoned_bakery exists in captions: True\n",
    "# ID abandoned_church exists in captions: True\n",
    "# ID abandoned_construction exists in captions: True\n",
    "# Split into 651 train and 49 val\n",
    "# Processing train set...\n",
    "# Processed 50/651 in train\n",
    "# Processed 100/651 in train\n",
    "# Processed 150/651 in train\n",
    "# Processed 200/651 in train\n",
    "# Processed 250/651 in train\n",
    "# Processed 300/651 in train\n",
    "# Processed 350/651 in train\n",
    "# Processed 400/651 in train\n",
    "# Processed 450/651 in train\n",
    "# Processed 500/651 in train\n",
    "# Processed 550/651 in train\n",
    "# Processed 600/651 in train\n",
    "# Processed 650/651 in train\n",
    "# âœ“ train: Processed 651 samples (0 missing)\n",
    "# âœ“ train: Created ../data/dataspace/polyhaven_tiny/cubediff_train.tar (1464.9 MB)\n",
    "# Processing val set...\n",
    "# âœ“ val: Processed 49 samples (0 missing)\n",
    "# âœ“ val: Created ../data/dataspace/polyhaven_tiny/cubediff_val.tar (110.5 MB)\n",
    "\n",
    "# Tar file sizes:\n",
    "# - Training tar: 1.5G\n",
    "# - Validation tar: 111M\n",
    "\n",
    "\n",
    "# ===== STEP 2: Simple Tar Verification =====\n",
    "# Verifying ../data/dataspace/polyhaven_tiny/cubediff_train.tar...\n",
    "# File size: 1464.9 MB\n",
    "# /opt/conda/lib/python3.10/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
    "#   warnings.warn(\n",
    "\n",
    "# Sample 1:\n",
    "#   Keys: ['__key__', '__url__', 'quarry_01_puresky.pt', '__local_path__', 'quarry_01_puresky.txt']\n",
    "#   ID: quarry_01_puresky\n",
    "#   Tensor shape: torch.Size([24, 64, 64])\n",
    "#   Caption: b'quarry 01 puresky'\n",
    "\n",
    "# Sample 2:\n",
    "#   Keys: ['__key__', '__url__', 'gray_pier.pt', '__local_path__', 'gray_pier.txt']\n",
    "#   ID: gray_pier\n",
    "#   Tensor shape: torch.Size([24, 64, 64])\n",
    "#   Caption: b'gray pier'\n",
    "\n",
    "# Sample 3:\n",
    "#   Keys: ['__key__', '__url__', 'neuer_zollhof.pt', '__local_path__', 'neuer_zollhof.txt']\n",
    "#   ID: neuer_zollhof\n",
    "#   Tensor shape: torch.Size([24, 64, 64])\n",
    "#   Caption: b'neuer zollhof'\n",
    "\n",
    "# Found 651 samples with keys: {'drackenstein_quarry.txt', 'georgentor.txt', 'small_empty_room_2.pt', 'nagoya_wall_path.txt', 'rostock_arches.pt', 'crosswalk.pt', 'colosseum.txt', 'cyclorama_hard_light.txt', 'childrens_hospital.txt', 'snowy_cemetery.pt', 'little_paris_under_tower.txt', 'je_gray_park.txt', 'pump_station.txt', 'abandoned_church.pt', 'sunset_fairway.txt', 'evening_road_01.txt', 'between_bridges.pt', 'qwantani_late_afternoon.pt', 'rogland_sunset.pt', 'fouriesburg_mountain_lookout.txt', 'palermo_square.pt', 'beach_parking.pt', 'lakeside_sunrise.txt', 'autumn_hockey.txt', 'leibstadt.pt', 'boma.txt', 'skylit_garage.pt', 'dikhololo_night.pt', 'resting_place.txt', 'fireplace.txt', 'blue_grotto.pt', 'ehingen_hillside.pt', 'lenong_1.pt', 'abandoned_bakery.pt', 'lapa.txt', 'hotel_room.pt', 'autumn_ground.pt', 'qwantani_patio.txt', 'quarry_02.txt', 'overcast_soil_2.pt', 'qwantani_dawn.pt', 'snowy_forest_path_02.txt', 'geislingen_an_der_steige.txt', 'abandoned_tank_farm_04.txt', 'kiara_7_late-afternoon.pt', 'modern_buildings_night.txt', 'gothic_manor_01.pt', 'kiara_7_late-afternoon.txt', 'large_corridor.txt', 'signal_hill_dawn.txt', 'small_empty_room_2.txt', 'carpentry_shop_01.txt', 'sunset_forest.txt', 'konzerthaus.pt', 'orlando_stadium.txt', 'satara_night_no_lamps.pt', 'brown_photostudio_02.txt', 'boma.pt', 'noga.txt', 'studio_garden.txt', 'indoor_pool.pt', 'kloppenheim_06_puresky.pt', 'kloofendal_43d_clear_puresky.txt', 'syferfontein_0d_clear.pt', 'modern_buildings.txt', 'quarry_01_puresky.pt', 'mutianyu.pt', 'misty_farm_road.txt', 'blaubeuren_hillside.txt', 'distribution_board.txt', 'sculpture_exhibition.txt', 'minedump_flats.txt', 'abandoned_tank_farm_01.pt', 'stream.pt', 'konigsallee.pt', 'mealie_road.pt', 'alps_field.pt', 'sunflowers.pt', 'snow_field_2.txt', 'castle_zavelstein_cellar.txt', 'red_wall.pt', 'sunset_fairway.pt', 'lakes.pt', 'hotel_rooftop_balcony.pt', 'etzwihl.pt', 'dark_autumn_forest.txt', 'qwantani_dusk_2.txt', 'storeroom.txt', 'felsenlabyrinth.pt', 'missile_launch_facility_01.txt', 'approaching_storm.txt', 'snow_field_2_puresky.pt', 'cannon.txt', 'provence_studio.txt', 'autumn_hockey.pt', 'cape_hill.txt', 'lenong_3.txt', 'docklands_01.pt', 'rural_graffiti_tower.pt', 'residential_garden.txt', 'kloppenheim_01.txt', 'qwantani_moon_noon.pt', 'outdoor_workshop.txt', 'nature_reserve_forest.txt', 'quarry_04_puresky.pt', 'simons_town_rocks.txt', 'kloppenheim_03.pt', 'pedestrian_overpass.pt', 'snowy_field.pt', 'abandoned_hopper_terminal_04.pt', 'limpopo_golf_course.txt', 'dresden_square.pt', 'small_harbour_sunset.pt', 'lakeside_dawn.pt', 'red_hill_curve.txt', 'hikers_cave.pt', 'reading_room.txt', 'small_empty_room_1.pt', 'snow_field_puresky.pt', 'aloe_farm_shade_house.pt', 'kloofendal_38d_partly_cloudy_puresky.pt', 'pond.pt', 'furry_clouds.pt', 'construction_yard.pt', 'river_walk_1.pt', 'abandoned_factory_canteen_02.txt', 'dresden_station_night.pt', 'hayloft.pt', 'driving_school.txt', 'pillars.pt', 'moonlit_golf.txt', 'derelict_underpass.txt', 'between_bridges.txt', 'small_harbor_01.txt', 'rosendal_park_sunset.pt', 'qwantani_puresky.pt', 'mosaic_tunnel.txt', 'christmas_photo_studio_03.txt', 'resting_place.pt', 'small_cathedral.pt', 'brown_photostudio_01.txt', 'belfast_open_field.txt', 'secluded_beach.txt', 'machine_shop_03.pt', 'missile_launch_facility_01.pt', 'summer_stage_02.txt', 'kart_club.txt', 'ostrich_road.txt', 'cyclorama_hard_light.pt', 'sandsloot.txt', 'abandoned_tank_farm_05.txt', 'machine_shop_03.txt', 'small_rural_road.pt', 'aft_lounge.txt', 'snowy_forest.txt', 'solitude_night.txt', 'museumplein.txt', 'phone_shop.pt', 'portland_landing_pad.pt', 'eilenriede_park.pt', 'studio_small_06.pt', 'kiara_5_noon.pt', 'reichstag_1.txt', 'sabie_tent.pt', 'quarry_cloudy.txt', 'dikhololo_sunset.txt', 'rustig_koppie.txt', 'old_room.pt', 'reinforced_concrete_01.pt', 'shady_patch.txt', 'kloofendal_misty_morning.pt', 'belfast_sunset.pt', 'rustig_koppie.pt', 'old_apartments_walkway.txt', 'stuttgart_suburbs.pt', 'roof_garden.pt', 'montorfano.txt', 'abandoned_pathway.txt', 'brown_photostudio_06.pt', 'dry_hay_field.txt', 'rathaus.txt', 'music_hall_02.pt', 'pizzo_pernice.txt', 'gray_pier.txt', 'misty_dawn.txt', 'kloppenheim_02_puresky.pt', 'snowy_forest_path_02.pt', 'quarry_02.pt', 'night_bridge.txt', 'forgotten_miniland.txt', 'noga.pt', 'bell_park_dawn.pt', 'kloetzle_blei.txt', 'clarens_night_01.pt', 'glass_passage.txt', 'peppermint_powerplant.txt', 'dresden_moat.txt', 'lakeside.pt', 'ehingen_hillside.txt', 'anniversary_lounge.pt', 'garage.txt', 'circus_arena.pt', 'small_empty_room_3.pt', 'cambridge.txt', 'kiara_2_sunrise.txt', 'factory_yard.pt', 'childrens_hospital.pt', 'piazza_bologni.pt', 'qwantani.txt', 'small_empty_room_3.txt', 'pretoria_gardens.txt', 'aristea_wreck_puresky.txt', 'modern_bathroom.pt', 'bismarckturm_hillside.txt', 'canary_wharf.pt', 'museum_of_history.pt', 'fouriesburg_mountain_midday.pt', 'overcast_soil_puresky.txt', 'peppermint_powerplant_2.txt', 'delta_2.txt', 'san_giuseppe_bridge.pt', 'industrial_sunset_02.pt', 'blue_lagoon_night.txt', 'small_cave.txt', 'small_rural_road_02.pt', 'golden_bay.txt', 'rocky_ridge_puresky.pt', 'flower_road.txt', 'mosaic_tunnel.pt', 'surgery.pt', 'old_bus_depot.pt', 'roofless_ruins.pt', 'factory_yard.txt', 'royal_esplanade.pt', 'spaichingen_hill.pt', 'empty_warehouse_01.txt', 'hamburg_canal.txt', 'passendorf_snow.txt', 'dam_road.txt', 'promenade_de_vidy.txt', 'pedestrian_overpass.txt', 'kiara_3_morning.pt', 'red_hill_cloudy.txt', 'goegap.txt', 'freight_station.txt', 'old_bus_depot.txt', 'kiara_9_dusk.txt', 'small_rural_road_02.txt', 'pump_station.pt', 'countrytrax_midday.txt', 'fouriesburg_mountain_cloudy.txt', 'derelict_overpass.pt', 'gamrig.txt', 'blouberg_sunrise_1.txt', 'qwantani_mid_morning.pt', 'farm_field_puresky.txt', 'blaubeuren_night.pt', 'rathaus.pt', 'misty_pines.pt', 'red_hill_cloudy.pt', 'old_tree_in_city_park.txt', 'shanghai_riverside.txt', 'autumn_road.txt', 'cinema_hall.txt', 'sunset_forest.pt', 'golf_course_sunrise.pt', 'greenwich_park.txt', 'old_quarry_gerlingen.pt', 'shudu_lake.pt', 'industrial_pipe_and_valve_02.txt', 'ballawley_park.txt', 'near_the_river_02.pt', 'farm_field_puresky.pt', 'lythwood_lounge.txt', 'green_sanctuary.txt', 'kloofendal_43d_clear.pt', 'kloppenheim_05_puresky.pt', 'sepulchral_chapel_basement.txt', 'autumn_field.txt', 'bergen.pt', 'hospital_room.txt', 'autumn_forest_04.pt', 'christmas_photo_studio_06.txt', 'herkulessaulen.txt', 'mossy_forest.pt', 'blender_institute.pt', 'modern_buildings_2.txt', 'simons_town_rocks.pt', 'sunflowers.txt', 'rocky_ridge.txt', 'schadowplatz.pt', 'museum_of_ethnography.pt', 'rosendal_park_sunset.txt', 'moulton_falls_train_tunnel_east.txt', 'abandoned_slipway.txt', 'metro_noord.pt', 'rustig_koppie_puresky.txt', 'kloppenheim_02.txt', 'qwantani_moon_noon.txt', 'abandoned_workshop_02.txt', 'simons_town_road.txt', 'suburban_parking_area.pt', 'abandoned_hopper_terminal_02.txt', 'sterkspruit_falls.txt', 'fouriesburg_mountain_lookout_2.txt', 'old_apartments_walkway.pt', 'aerodynamics_workshop.txt', 'gear_store.pt', 'quattro_canti.txt', 'evening_road_01.pt', 'neuer_zollhof.txt', 'creepy_bathroom.pt', 'street_lamp.pt', 'park_bench.pt', 'abandoned_tank_farm_05.pt', 'small_rural_road.txt', 'peppermint_powerplant_2.pt', 'hanger_exterior_cloudy.pt', 'netball_court.pt', 'harties.pt', '__url__', 'blue_grotto.txt', 'autoshop_01.pt', 'sandsloot.pt', 'kiara_8_sunset.pt', 'solitude_night.pt', 'pillars.txt', 'harvest.txt', 'lebombo.pt', 'courtyard.txt', 'rogland_overcast.pt', 'cloud_layers.txt', 'monte_scherbelino.txt', 'spaichingen_hill.txt', 'binnenalster.txt', 'golden_gate_hills.txt', 'kloppenheim_05.pt', 'satara_night_no_lamps.txt', 'cloudy_vondelpark.txt', 'countrytrax_midday.pt', 'museumplein.pt', 'kloofendal_38d_partly_cloudy.txt', 'autumn_forest_03.txt', 'dark_autumn_forest.pt', 'aloe_farm_shade_house.txt', 'dam_bridge.txt', 'autumn_forest_02.pt', 'artist_workshop.pt', 'syferfontein_18d_clear_puresky.txt', 'kloofendal_48d_partly_cloudy_puresky.pt', 'monbachtal_riverbank.pt', 'studio_small_08.pt', 'aviation_museum_hill.pt', 'dikhololo_sunset.pt', 'abandoned_tiled_room.pt', 'palermo_square.txt', 'sterkspruit_falls.pt', 'hamburg_hbf.pt', 'rooftop_night.pt', 'pizzo_pernice_puresky.txt', 'abandoned_waterworks.txt', 'bismarckturm.txt', 'resting_place_2.pt', 'greenwich_park_02.pt', 'graveyard_pathways.txt', 'dry_hay_field.pt', 'industrial_sunset_puresky.pt', 'drakensberg_solitary_mountain.pt', 'soliltude.pt', 'lilienstein.pt', 'leibstadt.txt', 'greenwich_park_03.pt', 'round_platform.txt', 'bethnal_green_entrance.pt', 'sunny_vondelpark.txt', 'qwantani_night.pt', 'dam_bridge.pt', 'monks_forest.pt', 'neurathen_rock_castle.pt', 'carpentry_shop_01.pt', 'rostock_arches.txt', 'lenong_3.pt', 'ox_bridge_morning.pt', 'modern_bathroom.txt', 'qwantani.pt', 'signal_hill_sunrise.txt', 'autumn_meadow.txt', 'mirrored_hall.txt', 'kloppenheim_07_puresky.txt', 'klippad_dawn_1.pt', 'qwantani_dusk_2.pt', 'abandoned_church.txt', 'dry_cracked_lake.txt', 'quattro_canti.pt', 'cinema_lobby.pt', 'bloem_hill_01.txt', 'rotes_rathaus.txt', 'country_club.pt', 'lythwood_room.pt', 'green_point_park.txt', 'cedar_bridge.txt', 'rotes_rathaus.pt', 'rogland_overcast.txt', 'distribution_board.pt', 'mpumalanga_veld_puresky.txt', 'abandoned_tank_farm_03.txt', 'acoustical_shell.txt', 'dam_wall.txt', 'sisulu.txt', 'air_museum_playground.pt', 'abandoned_hopper_terminal_02.pt', 'konzerthaus.txt', 'abandoned_construction.txt', 'docklands_02.pt', 'fouriesburg_mountain_cloudy.pt', 'schachen_forest.txt', 'hochsal_forest.pt', 'sunset_jhbcentral.txt', 'autumn_meadow.pt', 'pylons.txt', 'quarry_04_puresky.txt', 'autumn_forest_01.txt', 'beach_cloudy_bridge.pt', 'aviation_museum.pt', 'snowy_cemetery.txt', 'burnt_warehouse.txt', 'harties_cliff_view.pt', 'lakeside_night.txt', 'anniversary_lounge.txt', 'dalkey_view.txt', 'old_hall.txt', 'ehingen_hillside_02.txt', 'rostock_laage_airport.txt', 'rooitou_park.txt', 'neon_photostudio.pt', 'subway_entrance.pt', 'leadenhall_market.txt', 'hospital_room_2.txt', 'moulton_falls_train_tunnel_east.pt', 'red_hill_straight.pt', 'mealie_road.txt', 'crystal_falls.txt', 'derelict_highway_midday.pt', 'hikers_cave.txt', 'dry_orchard_meadow.pt', 'brick_factory_01.txt', 'rural_winter_roadside.pt', 'dry_cracked_lake.pt', 'snow_field.txt', 'abandoned_hall_01.txt', 'small_hangar_02.txt', 'future_parking.pt', 'cabin.txt', 'brown_photostudio_07.txt', 'frozen_lake.txt', 'studio_small_08.txt', 'hall_of_mammals.txt', 'potsdamer_platz.pt', 'narrow_moonlit_road.txt', 'river_walk_2.pt', 'derelict_highway_noon.pt', 'horn-koppe_snow.pt', 'farm_sunset.txt', 'green_point_park.pt', 'music_hall_01.pt', 'lythwood_terrace.pt', 'christmas_photo_studio_02.pt', 'combination_room.txt', 'amphitheatre_zanzibar_fort.pt', 'abandoned_parking.pt', 'lakeside_dawn.txt', 'abandoned_hopper_terminal_03.txt', 'rosendal_park_sunset_puresky.pt', 'flamingo_pan.txt', 'skukuza_golf.txt', 'killesberg_park.pt', 'qwantani_noon.pt', 'potsdamer_platz.txt', 'champagne_castle_1.pt', 'cannon.pt', 'cayley_lookout.txt', 'spruit_dawn.txt', 'oberer_kuhberg.txt', 'binnenalster.pt', 'blue_lagoon.txt', 'lenong_1.txt', 'hangar_interior.pt', 'steinbach_field.pt', 'school_hall.pt', 'small_harbor_01.pt', 'lauter_waterfall.pt', 'greenwich_park.pt', 'night_bridge.pt', 'drackenstein_quarry_puresky.txt', 'snowy_hillside.pt', 'blau_river.pt', 'stream.txt', 'kloofendal_misty_morning.txt', 'poly_haven_studio.txt', 'lakeside_sunrise.pt', 'brown_photostudio_07.pt', 'small_harbor_02.pt', 'pylons.pt', 'flower_hillside.pt', 'derelict_highway_midday.txt', 'beach_cloudy_bridge.txt', 'eilenriede_labyrinth.txt', 'nkuhlu.txt', 'montorfano.pt', 'old_tree_in_city_park.pt', 'misty_farm_road.pt', 'ox_bridge_morning.txt', 'buikslotermeerplein.pt', 'abandoned_greenhouse.pt', 'limehouse.pt', 'small_empty_house.pt', 'forgotten_miniland.pt', 'kloofendal_28d_misty_puresky.txt', 'evening_meadow.pt', 'leadenhall_market.pt', 'entrance_hall.pt', 'ruckenkreuz.txt', 'summer_stage_02.pt', 'rosendal_plains_2.pt', 'moulton_station_train_tunnel_west.pt', 'chapel_day.txt', 'autumn_forest_02.txt', 'satara_night.pt', 'empty_workshop.txt', 'comfy_cafe.pt', 'reichstag_1.pt', 'hamburg_hbf.txt', 'kart_club.pt', 'outdoor_umbrellas.pt', 'evening_road_01_puresky.txt', 'delta_2.pt', 'suburban_field_02.pt', 'lonely_road_afternoon_puresky.pt', 'sisulu.pt', 'blaubeuren_outskirts.pt', 'brown_photostudio_06.txt', 'dresden_moat.pt', 'laufenurg_church.pt', 'alps_field.txt', 'castle_zavelstein_cellar.pt', 'fort_schanskop_morning.txt', 'small_empty_room_4.txt', 'clarens_midday.pt', 'museum_of_history.txt', 'monbachtal_riverbank.txt', 'autumn_field_puresky.txt', 'hanger_exterior_cloudy.txt', 'lythwood_field.txt', 'frozen_lake.pt', 'quarry_01.txt', 'suburban_field_02.txt', 'herkulessaulen.pt', 'epping_forest_02.pt', 'orlando_stadium.pt', 'lythwood_room.txt', 'industrial_workshop_foundry.txt', 'aristea_wreck.pt', 'aviation_museum.txt', 'stuttgart_hillside.txt', 'bambanani_sunset.pt', 'signal_hill_sunrise.pt', 'drachenfels_cellar.txt', 'kloofendal_38d_partly_cloudy.pt', 'snowy_field.txt', 'small_hangar_02.pt', 'sunflowers_puresky.txt', 'abandoned_pathway.pt', 'learner_park.pt', 'kloppenheim_07_puresky.pt', 'dresden_square.txt', 'christmas_photo_studio_01.pt', 'derelict_highway_noon.txt', 'studio_small_07.txt', 'snowy_park_01.pt', 'gym_01.txt', 'kloofendal_43d_clear.txt', 'soliltude.txt', 'petit_port.txt', 'dry_orchard_meadow.txt', 'reinforced_concrete_02.txt', 'kiara_interior.pt', 'petit_port.pt', 'drachenfels_cellar.pt', 'learner_park.txt', 'hospital_room.pt', 'reinforced_concrete_02.pt', 'belfast_farmhouse.txt', 'lakeside_night.pt', 'rocky_ridge.pt', 'indoor_pool.txt', 'residential_garden.pt', 'bloem_train_track_cloudy.pt', 'greenwich_park_03.txt', 'kloofendal_48d_partly_cloudy.txt', 'canary_wharf.txt', 'altanka.pt', 'studio_small_03.pt', 'lauter_waterfall.txt', 'quarry_03.txt', 'studio_small_04.txt', 'derelict_underpass.pt', 'machine_shop_02.pt', 'basement_boxing_ring.pt', 'cayley_lookout.pt', 'kiara_1_dawn.txt', 'interior_construction.txt', 'storeroom.pt', 'citrus_orchard.txt', 'spiaggia_di_mondello.pt', 'billiard_hall.pt', 'epping_forest_01.txt', 'studio_small_05.txt', 'gothic_manor_01.txt', 'studio_small_06.txt', 'abandoned_hopper_terminal_03.pt', 'snow_field.pt', 'combination_room.pt', 'quarry_01_puresky.txt', 'epping_forest_02.txt', 'hotel_room.txt', 'secluded_beach.pt', 'qwantani_sunrise.pt', 'borghese_gardens.pt', 'rural_asphalt_road.pt', 'belvedere.txt', 'stierberg_sunrise.txt', 'mud_road_puresky.pt', 'monkstown_castle.pt', 'qwantani_morning.pt', 'phone_shop.txt', 'crystal_falls.pt', 'small_cave.pt', 'hausdorf_clear_sky.txt', 'drakensberg_solitary_mountain_puresky.pt', 'harvest.pt', 'rosendal_plains_2.txt', 'short_tunnel.txt', 'abandoned_tiled_room.txt', 'dry_meadow.txt', 'sunset_in_the_chalk_quarry.txt', 'kloofendal_38d_partly_cloudy_puresky.txt', 'golf_course_sunrise.txt', 'mall_parking_lot.txt', '__key__', 'blaubeuren_outskirts.txt', 'kloppenheim_04.txt', 'ballroom.pt', 'blue_photo_studio.txt', 'noon_grass.pt', 'citrus_orchard_road.txt', 'hall_of_finfish.pt', 'lago_disola.txt', 'docklands_02.txt', 'arboretum.txt', 'stuttgart_suburbs.txt', 'near_the_river_01.txt', 'artist_workshop.txt', 'bergen.txt', 'docklands_01.txt', 'rosendal_park_sunset_puresky.txt', 'modern_buildings.pt', 'overcast_soil.txt', 'outdoor_workshop.pt', 'machine_shop_01.txt', 'lake_pier.pt', 'parched_canal.pt', 'sunset_jhbcentral.pt', 'photo_studio_01.txt', 'studio_small_03.txt', 'music_hall_02.txt', 'monks_forest.txt', 'rosendal_mountain_midmorning.txt', 'hamburg_canal.pt', 'modern_buildings_night.pt', 'missile_launch_facility_02.txt', 'cambridge.pt', 'stone_alley_03.txt', 'dresden_station_night.txt', 'lago_disola.pt', 'small_empty_room_4.pt', 'qwantani_sunset.pt', 'river_rocks.pt', 'drakensberg_solitary_mountain.txt', 'moonlit_golf.pt', 'abandoned_parking.txt', 'farm_field.pt', 'blouberg_sunrise_2.txt', 'hochsal_forest.txt', 'hall_of_mammals.pt', 'lot_01.pt', 'spree_bank.txt', 'kiara_9_dusk.pt', 'outdoor_umbrellas.txt', 'abandoned_factory_canteen_02.pt', 'autumn_park.pt', 'courtyard_night.pt', 'red_hill_straight.txt', 'studio_small_09.pt', 'abandoned_factory_canteen_01.txt', 'sepulchral_chapel_rotunda.pt', 'scythian_tombs_2.pt', 'dikhololo_night.txt', 'evening_meadow.txt', 'pretville_cinema.txt', 'kloppenheim_06.pt', 'railway_bridges.pt', 'steinbach_field.txt', 'klippad_sunrise_2.pt', 'squash_court.txt', 'snowy_forest_path_01.txt', 'roof_garden.txt', 'abandoned_tank_farm_02.pt', 'autumn_road.pt', 'phalzer_forest_01.txt', 'quarry_cloudy.pt', 'blouberg_sunrise_2.pt', 'abandoned_waterworks.pt', 'air_museum_playground.txt', 'small_workshop.pt', 'qwantani_puresky.txt', 'cape_hill.pt', 'stierberg_sunrise.pt', 'interior_construction.pt', 'blouberg_sunrise_1.pt', 'industrial_sunset_02_puresky.pt', 'syferfontein_0d_clear.txt', 'balcony.pt', 'dry_field.txt', 'irish_institute.txt', 'abandoned_games_room_02.txt', 'comfy_cafe.txt', 'scythian_tombs.pt', 'borghese_gardens.txt', 'modern_buildings_2.pt', 'derelict_overpass.txt', 'rural_crossroads.txt', 'studio_small_02.txt', 'kloofendal_28d_misty_puresky.pt', 'suburban_parking_area.txt', 'hilly_terrain_01_puresky.pt', 'cloudy_cliffside_road.txt', 'industrial_sunset.txt', 'horn-koppe_snow.txt', 'preller_drive.pt', 'pool.txt', 'qwantani_patio.pt', 'reinforced_concrete_01.txt', 'kiara_1_dawn.pt', 'bloem_train_track_cloudy.txt', 'netball_court.txt', 'neuer_zollhof.pt', 'autoshop_01.txt', 'belfast_sunset_puresky.txt', 'missile_launch_facility_03.txt', 'studio_small_02.pt', 'sepulchral_chapel_basement.pt', 'st_fagans_interior.txt', 'balcony.txt', 'rolling_hills.txt', 'lush_dirt_path.txt', 'epping_forest_01.pt', 'rural_asphalt_road.txt', 'concrete_tunnel.txt', 'kloppenheim_06.txt', 'flower_hillside.txt', 'farm_sunset.pt', 'kloppenheim_01.pt', 'forest_grove.txt', 'small_harbour_sunset.txt', 'lakeside.txt', 'minedump_flats.pt', 'kloofendal_43d_clear_puresky.pt', 'summer_stage_01.pt', 'en_suite.txt', 'je_gray_02.pt', 'preller_drive.txt', 'gum_trees.txt', 'circus_maximus_2.pt', 'abandoned_tank_farm_01.txt', 'narrow_moonlit_road.pt', 'st_peters_square_night.pt', 'large_corridor.pt', 'snowy_hillside.txt', 'aircraft_workshop_01.txt', 'hilly_terrain_01.pt', 'drakensberg_solitary_mountain_puresky.txt', 'little_paris_under_tower.pt', 'fouriesburg_mountain_midday.txt', 'pretville_street.txt', 'old_hall.pt', 'qwantani_sunset.txt', 'resting_place_2.txt', 'palermo_park.txt', 'surgery.txt', 'garden_nook.pt', 'arboretum.pt', 'shanghai_riverside.pt', 'lookout.txt', 'circus_maximus_1.pt', 'circus_maximus_1.txt', 'geislingen_an_der_steige.pt', 'dreifaltigkeitsberg.txt', 'birbeck_street_underpass.pt', 'forest_cave.txt', 'pretoria_gardens.pt', 'aristea_wreck_puresky.pt', 'de_balie.pt', 'construction_yard.txt', 'abandoned_bakery.txt', 'rocky_ridge_puresky.txt', 'cobblestone_street_night.txt', 'red_hill_curve.pt', 'lakes.txt', 'photo_studio_london_hall.txt', 'rooftop_night.txt', 'abandoned_slipway.pt', 'ostrich_road.pt', 'georgentor.pt', 'decor_shop.txt', 'summer_stage_01.txt', 'snow_field_2.pt', 'brown_photostudio_01.pt', 'monkstown_castle.txt', 'spruit_sunrise.pt', 'belfast_farmhouse.pt', 'parched_canal.txt', 'kloppenheim_02.pt', 'chapel_day.pt', 'mossy_forest.txt', 'eilenriede_park.txt', 'bismarckturm_hillside.pt', 'st_fagans_interior.pt', 'rural_winter_roadside.txt', 'rosendal_mountain_midmorning.pt', 'blue_lagoon_night.pt', 'evening_road_01_puresky.pt', 'dancing_hall.pt', 'killesberg_park.txt', 'garden_nook.txt', 'boiler_room.pt', 'bismarckturm.pt', 'abandoned_tank_farm_02.txt', 'ehingen_hillside_02.pt', 'street_lamp.txt', 'poly_haven_studio.pt', 'rogland_sunset.txt', 'dry_meadow.pt', 'hilly_terrain_01_puresky.txt', 'glencairn_expressway.pt', 'mud_road_puresky.txt', 'kiara_2_sunrise.pt', 'dusseldorf_bridge.pt', 'sunny_vondelpark.pt', 'abandoned_factory_canteen_01.pt', 'rural_crossroads.pt', 'kloppenheim_01_puresky.txt', 'klippad_sunrise_1.pt', 'railway_bridges.txt', 'small_cathedral_02.txt', 'industrial_sunset.pt', 'christmas_photo_studio_04.pt', 'goegap_road.txt', 'christmas_photo_studio_06.pt', 'courtyard.pt', 'muddy_autumn_forest.pt', 'piazza_bologni.txt', 'photo_studio_01.pt', 'pond_bridge_night.pt', 'drackenstein_quarry.pt', 'medieval_cafe.pt', 'blue_photo_studio.pt', 'marry_hall.txt', 'subway_entrance.txt', 'reading_room.pt', 'mpumalanga_veld_puresky.pt', 'kloppenheim_03_puresky.txt', 'burnt_warehouse.pt', 'abandoned_workshop.txt', 'scythian_tombs.txt', 'qwantani_afternoon.pt', 'ninomaru_teien.pt', 'rosendal_plains_1.pt', 'misty_pines.txt', 'colorful_studio.txt', 'pretville_cinema.pt', 'muddy_autumn_forest.txt', 'rooitou_park.pt', 'rhodes_memorial.pt', 'kiara_6_afternoon.txt', 'small_harbour_morning.txt', 'belfast_sunset.txt', 'small_hangar_01.txt', 'san_giuseppe_bridge.txt', 'small_workshop.txt', 'gum_trees.pt', 'bell_park_dawn.txt', 'st_peters_square_night.txt', 'abandoned_workshop_02.pt', 'partial_eclipse.pt', 'mutianyu.txt', 'industrial_sunset_02_puresky.txt', 'blaubeuren_church_square.txt', 'qwantani_noon.txt', 'creepy_bathroom.txt', 'royal_esplanade.txt', 'cloud_layers.pt', 'illovo_beach_balcony.pt', 'old_room.txt', 'bank_vault.txt', 'basement_boxing_ring.txt', 'kloppenheim_04.pt', 'dam_road.pt', 'noon_grass.txt', 'boiler_room.txt', 'metro_vijzelgracht.pt', 'kloppenheim_03_puresky.pt', 'hausdorf_clear_sky.pt', 'schachen_forest.pt', 'kloppenheim_02_puresky.txt', 'brown_photostudio_05.txt', 'fish_eagle_hill.pt', 'piazza_martin_lutero.pt', 'signal_hill_dawn.pt', 'railway_bridge_02.txt', 'autumn_forest_01.pt', 'simons_town_harbour.pt', 'qwantani_dusk_1.pt', 'mall_parking_lot.pt', 'brown_photostudio_03.txt', 'studio_small_09.txt', 'river_rocks.txt', 'spruit_sunrise.txt', 'cedar_bridge.pt', 'mpumalanga_veld.pt', 'birbeck_street_underpass.txt', 'immenstadter_horn.pt', 'champagne_castle_1.txt', 'autumn_park.txt', 'missile_launch_facility_02.pt', 'promenade_de_vidy.pt', 'kiara_5_noon.txt', 'illovo_beach_balcony.txt', 'meadow_2.pt', 'dam_wall.pt', 'rogland_moonlit_night.txt', 'je_gray_park.pt', 'stone_alley.pt', 'brown_photostudio_04.pt', 'snow_field_puresky.txt', 'clarens_night_01.txt', 'colorful_studio.pt', 'meadow.txt', 'chinese_garden.pt', 'simons_town_road.pt', 'sunset_in_the_chalk_quarry.pt', 'abandoned_tank_farm_03.pt', 'fireplace.pt', 'autumn_crossing.txt', 'kloetzle_blei.pt', 'pizzo_pernice.pt', 'pizzo_pernice_puresky.pt', 'future_parking.txt', 'art_studio.pt', 'art_studio.txt', 'autumn_forest_03.pt', 'christmas_photo_studio_03.pt', 'brick_factory_02.txt', 'aviation_museum_hill.txt', 'quarry_04.pt', 'schadowplatz.txt', 'auto_service.txt', 'partial_eclipse.txt', 'small_cathedral.txt', 'cinema_hall.pt', 'small_hangar_01.pt', 'nature_reserve_forest.pt', 'nagoya_wall_path.pt', 'oberer_kuhberg.pt', 'abandoned_hopper_terminal_04.txt', 'medieval_cafe.txt', 'approaching_storm.pt', 'marry_hall.pt', 'moonless_golf.txt', 'bank_vault.pt', 'sepulchral_chapel_rotunda.txt', 'monte_scherbelino.pt', 'pond_bridge_night.txt', 'snowy_park_01.txt', 'gamrig.pt', 'kloppenheim_03.txt', 'kloppenheim_01_puresky.pt', 'snowy_forest.pt', 'pump_house.txt', 'spiaggia_di_mondello.txt', 'qwantani_mid_morning.txt', 'qwantani_late_afternoon.txt', 'ouchy_pier.txt', 'christmas_photo_studio_01.txt', 'pump_house.pt', 'kloofendal_28d_misty.pt', 'industrial_pipe_and_valve_02.pt', 'kloofendal_misty_morning_puresky.pt', 'sunflowers_puresky.pt', 'studio_garden.pt', 'beach_parking.txt', 'kloofendal_28d_misty.txt', 'meadow_2.txt', 'piazza_martin_lutero.txt', 'studio_small_05.pt', 'railway_bridge_02.pt', 'bush_restaurant.pt', 'overcast_soil.pt', 'cliffside.txt', 'klippad_sunrise_2.txt', 'kloofendal_48d_partly_cloudy_puresky.txt', 'qwantani_moonrise.txt', 'near_the_river_02.txt', 'flamingo_pan.pt', 'shudu_lake.txt', 'pine_attic.pt', 'circus_maximus_2.txt', 'kiara_8_sunset.txt', 'freight_station.pt', 'moulton_station_train_tunnel_west.txt', 'dry_field.pt', 'limpopo_golf_course.pt', 'kiara_4_mid-morning.txt', 'stone_alley_02.pt', 'pine_attic.txt', 'cinema_lobby.txt', 'stone_alley.txt', 'spree_bank.pt', 'industrial_workshop_foundry.pt', 'fouriesburg_mountain_lookout_2.pt', 'orbita.pt', 'lapa.pt', 'dalkey_view.pt', 'je_gray_02.txt', 'ballroom.txt', 'blau_river.txt', 'christmas_photo_studio_02.txt', 'laufenurg_church.txt', 'pool.pt', 'suburban_field_01.txt', 'qwantani_sunrise.txt', 'cobblestone_street_night.pt', 'furry_clouds.txt', 'cave_wall.txt', 'museum_of_ethnography.txt', 'country_club.txt', 'stadium_01.pt', 'autumn_field_puresky.pt', 'irish_institute.pt', 'industrial_sunset_puresky.txt', 'music_hall_01.txt', 'dusseldorf_bridge.txt', 'kiara_interior.txt', 'colosseum.pt', 'blaubeuren_church_square.pt', 'golden_bay.pt', 'bush_restaurant.txt', 'chapmans_drive.pt', 'kloppenheim_05.txt', 'kloppenheim_05_puresky.txt', 'gear_store.txt', 'kloofendal_48d_partly_cloudy.pt', 'rural_landscape.pt', 'overcast_soil_puresky.pt', 'piazza_san_marco.pt', 'hall_of_finfish.txt', 'qwantani_morning.txt', 'etzwihl.txt', 'felsenlabyrinth.txt', 'hotel_rooftop_balcony.txt', 'brown_photostudio_03.pt', 'abandoned_games_room_01.txt', 'meadow.pt', 'snowy_forest_path_01.pt', 'overcast_soil_2.txt', 'brown_photostudio_05.pt', 'fish_hoek_beach.txt', 'klippad_dawn_1.txt', 'blaubeuren_night.txt', 'missile_launch_facility_03.pt', 'mud_road.txt', 'blue_lagoon.pt', 'abandoned_construction.pt', 'crosswalk.txt', 'small_cathedral_02.pt', 'empty_warehouse_01.pt', 'adams_place_bridge.pt', 'skate_park.pt', 'qwantani_night.txt', 'photo_studio_london_hall.pt', 'concrete_tunnel.pt', 'abandoned_greenhouse.txt', 'roofless_ruins.txt', 'aircraft_workshop_01.pt', 'aft_lounge.pt', 'lilienstein.txt', 'mirrored_hall.pt', 'rainforest_trail.txt', 'qwantani_dawn.txt', 'phalzer_forest_01.pt', 'kloofendal_overcast_puresky.pt', 'cloudy_cliffside_road.pt', 'stone_alley_02.txt', 'buikslotermeerplein.txt', 'rural_landscape.txt', 'gray_pier.pt', 'fish_hoek_beach.pt', 'park_bench.txt', 'harties_cliff_view.txt', 'harties.txt', 'cabin.pt', 'bethnal_green_entrance.txt', 'skukuza_golf.pt', 'driving_school.pt', 'aristea_wreck.txt', 'brick_factory_01.pt', 'palermo_park.pt', 'old_quarry_gerlingen.txt', 'rostock_laage_airport.pt', 'brown_photostudio_02.pt', 'belfast_open_field.pt', 'small_empty_house.txt', 'school_hall.txt', 'autumn_field.pt', 'adams_place_bridge.txt', 'industrial_sunset_02.txt', 'de_balie.txt', 'snow_field_2_puresky.txt', 'ballawley_park.pt', 'christmas_photo_studio_04.txt', 'limehouse.txt', 'kiara_6_afternoon.pt', 'brick_factory_02.pt', 'misty_dawn.pt', 'passendorf_snow.pt', 'abandoned_games_room_01.pt', 'pink_sunrise.txt', 'graffiti_shelter.pt', 'mud_road.pt', 'hayloft.txt', 'acoustical_shell.pt', 'pink_sunrise.pt', 'small_harbour_morning.pt', 'amphitheatre_zanzibar_fort.txt', 'spruit_dawn.pt', 'qwantani_moonrise.pt', 'short_tunnel.pt', 'parking_garage.pt', 'ahornsteig.pt', 'citrus_orchard.pt', 'garage.pt', 'konigsallee.txt', 'goegap_road.pt', 'lonely_road_afternoon_puresky.txt', 'blender_institute.txt', 'scythian_tombs_2.txt', 'provence_studio.pt', 'lot_01.txt', 'birchwood.txt', 'eilenriede_labyrinth.pt', 'orbita.txt', 'studio_small_04.pt', 'lythwood_field.pt', 'gym_01.pt', 'auto_service.pt', 'small_harbor_02.txt', 'photo_studio_broadway_hall.txt', 'lythwood_terrace.txt', 'glencairn_expressway.txt', 'ninomaru_teien.txt', 'lush_dirt_path.pt', 'neon_photostudio.txt', 'autumn_forest_04.txt', 'kiara_4_mid-morning.pt', 'red_wall.txt', 'aerodynamics_workshop.pt', 'rural_graffiti_tower.txt', 'studio_small_01.pt', '__local_path__', 'studio_small_07.pt', 'old_depot.txt', 'kloppenheim_06_puresky.txt', 'paul_lobe_haus.pt', 'machine_shop_02.txt', 'citrus_orchard_road.pt', 'old_depot.pt', 'bloem_hill_01.pt', 'fort_schanskop_morning.pt', 'hochsal_field.txt', 'golden_gate_hills.pt', 'pond.txt', 'bell_park_pier.pt', 'forest_cave.pt', 'clarens_midday.txt', 'mpumalanga_veld.txt', 'altanka.txt', 'belvedere.pt', 'quarry_03.pt', 'qwantani_afternoon.txt', 'small_empty_room_1.txt', 'bell_park_pier.txt', 'lookout.pt', 'cave_wall.pt', 'syferfontein_18d_clear_puresky.pt', 'courtyard_night.txt', 'chinese_garden.txt', 'fouriesburg_mountain_lookout.pt', 'goegap.pt', 'lythwood_lounge.pt', 'hochsal_field.pt', 'graveyard_pathways.pt', 'portland_landing_pad.txt', 'moonless_golf.pt', 'sculpture_exhibition.pt', 'piazza_san_marco.txt', 'green_sanctuary.pt', 'ruckenkreuz.pt', 'glass_passage.pt', 'immenstadter_horn.txt', 'lebombo.txt', 'shady_patch.pt', 'ahornsteig.txt', 'greenwich_park_02.txt', 'quarry_01.pt', 'pretville_street.pt', 'qwantani_dusk_1.txt', 'kloofendal_misty_morning_puresky.txt', 'drackenstein_quarry_puresky.pt', 'rhodes_memorial.txt', 'near_the_river_01.pt', 'squash_court.pt', 'stone_alley_03.pt', 'abandoned_workshop.pt', 'blaubeuren_hillside.pt', 'machine_shop_01.pt', 'birchwood.pt', 'farm_field.txt', 'metro_noord.txt', 'river_walk_1.txt', 'chapmans_drive.txt', 'nkuhlu.pt', 'metro_vijzelgracht.txt', 'skylit_garage.txt', 'flower_road.pt', 'hangar_interior.txt', 'empty_workshop.pt', 'rosendal_plains_1.txt', 'graffiti_shelter.txt', 'simons_town_harbour.txt', 'autumn_ground.txt', 'studio_small_01.txt', 'klippad_sunrise_1.txt', 'rolling_hills.pt', 'suburban_field_01.pt', 'skate_park.txt', 'quarry_04.txt', 'brown_photostudio_04.txt', 'autumn_crossing.pt', 'dreifaltigkeitsberg.pt', 'sabie_tent.txt', 'river_walk_2.txt', 'kloofendal_overcast_puresky.txt', 'billiard_hall.txt', 'lake_pier.txt', 'skidpan.pt', 'abandoned_games_room_02.pt', 'neurathen_rock_castle.txt', 'hilly_terrain_01.txt', 'ouchy_pier.pt', 'stadium_01.txt', 'cliffside.pt', 'stuttgart_hillside.pt', 'en_suite.pt', 'abandoned_tank_farm_04.pt', 'photo_studio_broadway_hall.pt', 'forest_grove.pt', 'decor_shop.pt', 'paul_lobe_haus.txt', 'belfast_sunset_puresky.pt', 'rainforest_trail.pt', 'round_platform.pt', 'abandoned_hall_01.pt', 'peppermint_powerplant.pt', 'kiara_3_morning.txt', 'fish_eagle_hill.txt', 'dancing_hall.txt', 'circus_arena.txt', 'rogland_moonlit_night.pt', 'parking_garage.txt', 'satara_night.txt', 'skidpan.txt', 'entrance_hall.txt', 'cloudy_vondelpark.pt', 'rustig_koppie_puresky.pt', 'bambanani_sunset.txt', 'hospital_room_2.pt'}\n",
    "# Verifying ../data/dataspace/polyhaven_tiny/cubediff_val.tar...\n",
    "# File size: 110.5 MB\n",
    "\n",
    "# Sample 1:\n",
    "#   Keys: ['__key__', '__url__', 'floral_tent.pt', '__local_path__', 'floral_tent.txt']\n",
    "#   ID: floral_tent\n",
    "#   Tensor shape: torch.Size([24, 64, 64])\n",
    "#   Caption: b'floral tent'\n",
    "\n",
    "# Sample 2:\n",
    "#   Keys: ['__key__', '__url__', 'empty_play_room.pt', '__local_path__', 'empty_play_room.txt']\n",
    "#   ID: empty_play_room\n",
    "#   Tensor shape: torch.Size([24, 64, 64])\n",
    "#   Caption: b'empty play room'\n",
    "\n",
    "# Sample 3:\n",
    "#   Keys: ['__key__', '__url__', 'little_paris_eiffel_tower.pt', '__local_path__', 'little_paris_eiffel_tower.txt']\n",
    "#   ID: little_paris_eiffel_tower\n",
    "#   Tensor shape: torch.Size([24, 64, 64])\n",
    "#   Caption: b'little paris eiffel tower'\n",
    "\n",
    "# Found 49 samples with keys: {'gothic_manor_02.pt', 'stone_pines.txt', 'empty_play_room.txt', 'lenong_2.pt', 'niederwihl_forest.txt', 'blinds.pt', 'solitude_interior.txt', 'bathroom.pt', 'straw_rolls_field_01.txt', 'syferfontein_0d_clear_puresky.txt', 'rogland_clear_night.txt', 'studio_country_hall.pt', 'abandoned_hopper_terminal_01.pt', 'scythian_tombs_puresky.pt', 'photo_studio_loft_hall.txt', 'evening_field.txt', 'empty_play_room.pt', 'blocky_photo_studio.pt', 'school_quad.pt', 'syferfontein_18d_clear.txt', 'floral_tent.pt', 'emmarentia.txt', 'concrete_tunnel_02.pt', 'kloppenheim_07.txt', 'castel_st_angelo_roof.pt', 'safari_sunset.txt', 'dirt_bike_track_01.txt', 'syferfontein_18d_clear.pt', 'carpentry_shop_02.pt', 'bathroom.txt', 'bloem_train_track_clear.pt', 'kloppenheim_07.pt', 'shanghai_bund.txt', 'kloofendal_overcast.pt', 'old_outdoor_theater.txt', 'cayley_interior.txt', 'hansaplatz.txt', 'gym_entrance.txt', 'northcliff.pt', 'straw_rolls_field_01.pt', 'clarens_night_02.pt', 'kloofendal_overcast.txt', 'carpentry_shop_02.txt', 'industrial_pipe_and_valve_01.txt', 'floral_tent.txt', 'dirt_bike_track_01.pt', 'rooftop_day.pt', 'lenong_2.txt', 'shanghai_bund.pt', 'lot_02.pt', 'blocky_photo_studio.txt', 'bloem_train_track_clear.txt', '__local_path__', 'emmarentia.pt', 'school_quad.txt', 'blinds.txt', 'christmas_photo_studio_05.pt', 'rooftop_day.txt', 'park_parking.txt', 'klippad_dawn_2.txt', 'stone_pines.pt', 'safari_sunset.pt', 'klippad_dawn_2.pt', 'cayley_interior.pt', 'industrial_pipe_and_valve_01.pt', 'old_outdoor_theater.pt', 'photo_studio_loft_hall.pt', 'forest_slope.txt', 'castel_st_angelo_roof.txt', 'little_paris_eiffel_tower.pt', 'lonely_road_afternoon.pt', 'concrete_tunnel_02.txt', 'christmas_photo_studio_07.pt', 'christmas_photo_studio_05.txt', 'palermo_sidewalk.pt', 'studio_country_hall.txt', 'park_parking.pt', 'scythian_tombs_puresky.txt', 'rogland_clear_night.pt', 'solitude_interior.pt', 'gothic_manor_02.txt', 'lot_02.txt', 'forest_slope.pt', 'northcliff.txt', 'snowy_hillside_02.txt', 'snowy_hillside_02.pt', 'palermo_sidewalk.txt', 'hilltop_construction.txt', 'gym_entrance.pt', 'lonely_road_afternoon.txt', 'hilltop_construction.pt', 'syferfontein_0d_clear_puresky.pt', 'niederwihl_forest.pt', 'evening_field.pt', 'little_paris_eiffel_tower.txt', 'hansaplatz.pt', '__url__', '__key__', 'abandoned_hopper_terminal_01.txt', 'clarens_night_02.txt', 'christmas_photo_studio_07.txt'}\n",
    "\n",
    "# âœ… Both tar files appear valid\n",
    "\n",
    "\n",
    "# ===== STEP 3: Dataset Loading and Visualization =====\n",
    "# Loading dataset from ../data/dataspace/polyhaven_tiny/cubediff_train.tar...\n",
    "# /opt/conda/lib/python3.10/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
    "#   warnings.warn(\n",
    "\n",
    "# Batch 1:\n",
    "#   Batch size: 4\n",
    "#   Latent shape: torch.Size([4, 24, 64, 64])\n",
    "\n",
    "# Sample 1:\n",
    "#   ID: quarry_01_puresky\n",
    "#   Latent shape: torch.Size([24, 64, 64])\n",
    "#   Caption: quarry 01 puresky\n",
    "#   Error visualizing latent: Expected tensor with shape [6, C, H, W], got torch.Size([24, 64, 64])\n",
    "\n",
    "# Sample 2:\n",
    "#   ID: gray_pier\n",
    "#   Latent shape: torch.Size([24, 64, 64])\n",
    "#   Caption: gray pier\n",
    "#   Error visualizing latent: Expected tensor with shape [6, C, H, W], got torch.Size([24, 64, 64])\n",
    "\n",
    "# Sample 3:\n",
    "#   ID: neuer_zollhof\n",
    "#   Latent shape: torch.Size([24, 64, 64])\n",
    "#   Caption: neuer zollhof\n",
    "#   Error visualizing latent: Expected tensor with shape [6, C, H, W], got torch.Size([24, 64, 64])\n",
    "\n",
    "# Processed 3 samples from 1 batches\n",
    "\n",
    "\n",
    "# ===== VERIFICATION COMPLETE =====\n",
    "# If all verification steps passed, your CubeDiff data is ready for training!\n",
    "# Training tar: ../data/dataspace/polyhaven_tiny/cubediff_train.tar (1.5G)\n",
    "# Validation tar: ../data/dataspace/polyhaven_tiny/cubediff_val.tar (111M)\n",
    "# Sample visualizations: ./visualizations\n",
    "\n",
    "# ==================================================\n",
    "# root@af45057ae158:~/mluser/git/llm-cv-pano-cubediff/cl/data/dataspace/polyhaven_tiny# ls -lh\n",
    "# total 2.4G\n",
    "# -rw-r--r-- 1 root root 1.5G May 15 05:15 cubediff_train.tar\n",
    "# -rw-r--r-- 1 root root 111M May 15 05:15 cubediff_val.tar\n",
    "# drwxr-xr-x 2 root root  36K May 15 05:01 latents\n",
    "# -rw-r--r-- 1 root root 735M Apr 26 17:02 old_cubediff_train_with_mask_channel_2025_5_13.tar\n",
    "# -rw-r--r-- 1 root root  56M Apr 26 17:02 old_cubediff_val_with_mask_channel_2025_5_13.tar\n",
    "# drwxr-xr-x 2 root root  36K Apr 24 20:33 old_latents\n",
    "# drwxr-xr-x 2 root root  36K Apr 25 04:32 old_latents_with_mask_channel_2025_5_13\n",
    "# drwxr-xr-x 6 root root 4.0K Apr 25 04:27 raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a403ecf-0307-4b61-ad87-1990a95a6bfe",
   "metadata": {},
   "source": [
    "# install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cae304c5-8015-4638-82e9-cda785ac1cdf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/simple\n",
      "Collecting huggingface-hub==0.25.1\n",
      "  Downloading https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/5f/f1/15dc793cb109a801346f910a6b350530f2a763a6e83b221725a0bcc1e297/huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "Collecting transformers==4.35.2\n",
      "  Downloading https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/12/dd/f17b11a93a9ca27728e12512d167eb1281c151c4c6881d3ab59eb58f4127/transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting diffusers==0.25.1\n",
      "  Downloading https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/e4/c6/1f9768606c937e71c4d391307f395942c42d5567f538712dbf37b0cc0917/diffusers-0.25.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m135.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.25.1) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.25.1) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.25.1) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.25.1) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.25.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.25.1) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.25.1) (4.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (1.25.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (2024.11.6)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.35.2)\n",
      "  Downloading https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/1c/5d/cf5e122ce4f1a29f165b2a69dc33d1ff30bce303343d58a54775ddba5d51/tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2) (0.5.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers==0.25.1) (8.4.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers==0.25.1) (11.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers==0.25.1) (3.21.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.25.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.25.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.25.1) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.25.1) (2025.4.26)\n",
      "Installing collected packages: huggingface-hub, tokenizers, diffusers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.21.4\n",
      "    Uninstalling huggingface-hub-0.21.4:\n",
      "      Successfully uninstalled huggingface-hub-0.21.4\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.2\n",
      "    Uninstalling tokenizers-0.21.2:\n",
      "      Successfully uninstalled tokenizers-0.21.2\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.21.4\n",
      "    Uninstalling diffusers-0.21.4:\n",
      "      Successfully uninstalled diffusers-0.21.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.53.1\n",
      "    Uninstalling transformers-4.53.1:\n",
      "      Successfully uninstalled transformers-4.53.1\n",
      "Successfully installed diffusers-0.25.1 huggingface-hub-0.25.1 tokenizers-0.15.2 transformers-4.35.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 2025-7-7 Remove conflicting packages first to solve diffusers.is_torch_version issue that blocked torch.compile()\n",
    "# Since your code doesn't actually use PEFT (it uses full-rank fine-tuning), let's install compatible versions without PEFT:\n",
    "# !pip uninstall peft diffusers huggingface-hub -y\n",
    "\n",
    "# Install compatible versions without PEFT\n",
    "# !pip install diffusers==0.21.4 huggingface-hub==0.16.4 -i https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/simple\n",
    "\n",
    "# Upgrade to versions that work together\n",
    "# !pip install huggingface-hub==0.21.4 accelerate==1.0.1 -i https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/simple\n",
    "\n",
    "\n",
    "# 2025-7-7 Upgrade to latest compatible versions\n",
    "!pip install huggingface-hub==0.25.1 transformers==4.35.2 diffusers==0.25.1 -i https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15aedbc8-9c9e-442a-acb7-f611fecca411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/simple\n",
      "Collecting torch==2.1.2\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/03/f1/13137340776dd5d5bcfd2574c9c6dfcc7618285035cd77240496e5c1a79b/torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Collecting torchvision==0.16.2\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/da/ae/76bd3682465730dea7be21f36a8160a911a470de6f26228904f222e7fefe/torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "Collecting opencv-python==4.8.1.78\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/b7/8a/b2f7e1a434d56bf1d7570fc5941ace0847404e1032d7f1f0b8fed896568d/opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "Collecting opencv-contrib-python==4.8.1.78\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/32/9e/4dcc0bb70e3b365dc85b8f96c63e6a306653f7cc6ed061aa6cc7b2bddee7/opencv_contrib_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.8 MB)\n",
      "Collecting matplotlib==3.8.2\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/19/e5/a4ea514515f270224435c69359abb7a3d152ed31b9ee3ba5e63017461945/matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Collecting tqdm==4.66.1\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Collecting einops==0.7.0\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "Collecting xformers\n",
      "  Downloading https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/84/bb/7faaaeffbb120c6d4240586f323fed6756afe13e92cfe5ad582d155bde87/xformers-0.0.31.post1-cp39-abi3-manylinux_2_28_x86_64.whl (117.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.1/117.1 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (11.1.0)\n",
      "Collecting openexr\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/2b/0c/7e913f31293194dfa45f7e6093017cacc3c75e2b8742027dfeced547daba/openexr-3.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting opencv-python-headless\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/89/53/e19c21e0c4eb1275c3e2c97b081103b6dfb3938172264d283a519bf728b9/opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "Collecting wandb\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/83/8f/6bed9358cc33767c877b221d4f565e1ddf00caf4bbbe54d2e3bbc932c6a7/wandb-0.21.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
      "Collecting bitsandbytes\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/6b/1e/c26dbcb46cebb49fa6b17ff888966e6d8f306078b095a5df801a583549d0/bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
      "Collecting webdataset\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/d9/00/aca6beb3658dab4ed3dbb41a78e6e7f31342e0b41d28088f205525751601/webdataset-1.0.2-py3-none-any.whl (74 kB)\n",
      "Collecting timm\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/3b/14/10d0ea58a7580b8bd7c8d69420b3dc3a1deb890d4ff297deca9717689598/timm-1.0.16-py3-none-any.whl (2.5 MB)\n",
      "Collecting accelerate\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/91/d9/e044c9d42d8ad9afa96533b46ecc9b7aea893d362b3c52bd78fb9fe4d7b3/accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
      "Collecting deepspeed\n",
      "  Downloading https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/8c/45/1ddcf8f8500d90fad9f3396bfb1295462d46a747ddcbfafcd7714d46827e/deepspeed-0.17.2.tar.gz (1.6 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting imageio\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/cb/bd/b394387b598ed84d8d0fa90611a90bee0adc2021820ad5729f7ced74a8e2/imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Collecting diffusers==0.25.1\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/e4/c6/1f9768606c937e71c4d391307f395942c42d5567f538712dbf37b0cc0917/diffusers-0.25.1-py3-none-any.whl (1.8 MB)\n",
      "Collecting huggingface_hub==0.25.1\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/5f/f1/15dc793cb109a801346f910a6b350530f2a763a6e83b221725a0bcc1e297/huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "Collecting transformers==4.35.2\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/12/dd/f17b11a93a9ca27728e12512d167eb1281c151c4c6881d3ab59eb58f4127/transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (4.13.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/b6/9f/c64c03f49d6fbc56196664d05dba14e3a561038a81a638eeb47f4d4cfd48/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/eb/d5/c68b1d2cdfcc59e72e8a5949a37ddb22ae6cade80cd4a57a84d4c8b55472/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/7e/00/6b218edd739ecfc60524e585ba8e6b00554dd908de2c9c66c1af3e44e18d/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/44/31/4890b1c9abc496303412947fc7dcea3d14861720642b49e8ceed89636705/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/bc/1d/8de1e5c67099015c834315e333911273a8c6aaba78923dd1d1e25fc5f217/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/65/5b/cfaeebf25cd9fdec14338ccb16f6b2c4c7fa9163aefcf057d86b9cc248bb/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/a4/05/23f8f38eec3d28e4915725b233c24d8f1a33cb6540a882f7b54be1befa02/nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/da/d3/8057f0587683ed2fcd4dbfbdfdfa807b9160b809976099d36b8f60d08f03/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch==2.1.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/4d/22/91a8af421c8a8902dde76e6ef3db01b258af16c53d81e8c0d0dc13900a9e/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.2) (1.25.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib==3.8.2) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers==0.25.1) (8.4.0)\n",
      "Collecting regex!=2019.12.17 (from diffusers==0.25.1)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/f2/98/26d3830875b53071f1f0ae6d547f1d98e964dd29ad35cbf94439120bb67a/regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Collecting safetensors>=0.3.1 (from diffusers==0.25.1)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/a6/f8/dae3421624fcc87a89d42e1898a798bc7ff72c61f38973a65d60df8f124c/safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.25.1) (6.0.2)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.35.2)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/1c/5d/cf5e122ce4f1a29f165b2a69dc33d1ff30bce303343d58a54775ddba5d51/tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2) (12.4.99)\n",
      "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting xformers\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/ff/e3/ee90c62a3235152d4ea8e983a5eb7ac00b10582fee86aaadb11571c1ecba/xformers-0.0.31-cp39-abi3-manylinux_2_28_x86_64.whl (117.1 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/45/d0/4ed66b2d46bef4373f106b58361364cbd8ce53c85e60c8ea57ea254887bb/xformers-0.0.30-cp310-cp310-manylinux_2_28_x86_64.whl (31.5 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/55/4f/ef63f866ec7d3a23f78629604deaf379cd833fa4fd0cf7e6f8a77906f125/xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl (43.3 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/a1/44/7b27f60ec6f31f99cd5c2ee0553ab6c0bd7a289cc2abac076a859ddac143/xformers-0.0.29.post2-cp310-cp310-manylinux_2_28_x86_64.whl (44.3 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/28/1d/03356b31386a61162bccddf7fba6c792b4fe1159ad2af5f4b7879ce947ad/xformers-0.0.29.post1-cp310-cp310-manylinux_2_28_x86_64.whl (15.3 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/a4/63/cf772ebd81759ce93dbdbb6d0236092b8f570f90675d505dab2d560daab6/xformers-0.0.29-cp310-cp310-manylinux_2_28_x86_64.whl (15.3 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/02/56/d1a86f2c4a5a80e1f4926eef1ba69d6eb77ae823d36da7860984ca0b3421/xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "INFO: pip is still looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/07/6c/62ce963a51e7c400f3720e93b479ce4020b8447b4d1e8138ec460e21b9d3/xformers-0.0.28.post2-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/ca/24/3335df4d7c363188705be2808eb7e4bacfbfe23e3a4671c8f311236036d1/xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/7e/c9/a93741c2cc29dd44f361c801dd7e48f0d27617bf3951459578f20c61f511/xformers-0.0.28-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/04/69/f084d27545d130a960abb73fc84ad99f5260b3d98b55eef5dd065068055c/xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl (20.8 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/2b/20/2c00a2238e6b5cbad5ebc9cd6f60d6e5c28146a86fc02cfb9da3e14538db/xformers-0.0.27.post1-cp310-cp310-manylinux2014_x86_64.whl (20.8 MB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/3e/10/ce0d6e314b38ce8c438c04f5efc1498c8e68e4d9928cd5a2c046fc4f0923/xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl (164.1 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/32/e7/27003645ef99e7571fb6964cd2f39da3f1b3f3011aa00bb2d3ac9b790757/xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/5f/9b/f781a50d965717a2a2ea2c8d15e0f30deec8f9751a9874e850ba9ab0fadc/xformers-0.0.25.post1-cp310-cp310-manylinux2014_x86_64.whl (222.5 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/81/29/df65a2933a6a9acf19a90e0aef74b0bc69635bbe890204d5d03e7d89c85d/xformers-0.0.25-cp310-cp310-manylinux2014_x86_64.whl (222.5 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/78/c9/0cdbc2403666833302ab13f07b02b4556a5885b0542c7aa67f52d5ad0401/xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl (218.2 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/f4/89/ce8e936d3e64b3b565c16312dd6446d54f6e485f864130702c6b3b3cbe7c/xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2025.4.26)\n",
      "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-python-headless\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/dd/5c/c139a7876099916879609372bfa513b7f1257f7f1a908b0bdc1c2328241b/opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.10.21)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/01/a1/fc4856bd02d2097324fb7ce05b3021fb850f864b83ca765f6e37e92ff8ca/sentry_sdk-2.32.0-py2.py3-none-any.whl (356 kB)\n",
      "INFO: pip is looking at multiple versions of bitsandbytes to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting bitsandbytes\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/72/27/ec6ee3408e09e01ab05db07af5a97dc76db7bc18824cf5f5dbc98e1e08a4/bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/07/b7/cb5ce4d1a382cf53c19ef06c5fc29e85f5e129b4da6527dd207d90a5b8ad/bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "Collecting braceexpand (from webdataset)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/fa/93/e8c04e80e82391a6e51f218ca49720f64236bc824e92152a2633b74cf7ab/braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Collecting hjson (from deepspeed)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/1f/7f/13cd798d180af4bf4c0ceddeefba2b864a63c71645abc0308b768d67bb81/hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from deepspeed) (1.1.0)\n",
      "Collecting ninja (from deepspeed)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/eb/7a/455d2877fe6cf99886849c7f9755d897df32eaf3a0fba47b56e615f880f7/ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Collecting py-cpuinfo (from deepspeed)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/e0/a9/023730ba63db1e494a271cb018dcd361bd2c917ba7004c3e49d5daf795a2/py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting pydantic<3 (from wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/6a/c0/ec2b1c8712ca690e5d61979dee872603e92b8a32f94cc1b72d53beab008a/pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Requirement already satisfied: nvidia-ml-py in /opt/conda/lib/python3.10/site-packages (from deepspeed) (11.495.46)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3->wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/31/0d/c8f7593e6bc7066289bbc366f2235701dcbebcd1ff0ef8e64f6f239fb47d/pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3->wandb)\n",
      "  Using cached https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/packages/packages/17/69/cd203477f944c353c31bade965f880aa1061fd6bf05ded0726ca845b6ff7/typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.8.2) (1.17.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers==0.25.1) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.2) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.2) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Building wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.17.2-py3-none-any.whl size=1699944 sha256=2d3797c119bab699a576a546e647c96b635abbadf0ab1f0164f4c6ca5c157642\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/b5/43/90/57ed3d7a1f9fb26bd74304316b77bdffdce05941e5d8157a32\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: py-cpuinfo, hjson, braceexpand, webdataset, typing-inspection, triton, tqdm, sentry-sdk, safetensors, regex, pydantic-core, openexr, opencv-python-headless, opencv-python, opencv-contrib-python, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, imageio, einops, annotated-types, pydantic, nvidia-cusolver-cu12, nvidia-cudnn-cu12, matplotlib, huggingface_hub, wandb, torch, tokenizers, diffusers, xformers, transformers, torchvision, deepspeed, bitsandbytes, accelerate, timm\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.0.0\n",
      "    Uninstalling triton-3.0.0:\n",
      "      Successfully uninstalled triton-3.0.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.99\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.99:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.99\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.3.0.142\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.0.142:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.0.142\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.5.119\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.119:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.119\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.0.44\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.0.44:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.0.44\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.99\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.99:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.99\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.99\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.99:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.99\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.99\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.99:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.99\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.4.2.65\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.2.65:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.2.65\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.21\n",
      "    Uninstalling pydantic-1.10.21:\n",
      "      Successfully uninstalled pydantic-1.10.21\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.0.99\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.0.99:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.0.99\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.3\n",
      "    Uninstalling matplotlib-3.7.3:\n",
      "      Successfully uninstalled matplotlib-3.7.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0+cu124\n",
      "    Uninstalling torch-2.4.0+cu124:\n",
      "      Successfully uninstalled torch-2.4.0+cu124\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.19.0+cu124\n",
      "    Uninstalling torchvision-0.19.0+cu124:\n",
      "      Successfully uninstalled torchvision-0.19.0+cu124\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dataproc-jupyter-plugin 0.1.80 requires pydantic~=1.10.0, but you have pydantic 2.11.7 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires matplotlib<=3.7.3,>=3.2, but you have matplotlib 3.8.2 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires pydantic<2,>=1.8.1, but you have pydantic 2.11.7 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.8.1 annotated-types-0.7.0 bitsandbytes-0.45.5 braceexpand-0.1.7 deepspeed-0.17.2 diffusers-0.25.1 einops-0.7.0 hjson-3.1.0 huggingface_hub-0.25.1 imageio-2.37.0 matplotlib-3.8.2 ninja-1.11.1.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 opencv-contrib-python-4.8.1.78 opencv-python-4.8.1.78 opencv-python-headless-4.11.0.86 openexr-3.3.4 py-cpuinfo-9.0.0 pydantic-2.11.7 pydantic-core-2.33.2 regex-2024.11.6 safetensors-0.5.3 sentry-sdk-2.32.0 timm-1.0.16 tokenizers-0.15.2 torch-2.1.2 torchvision-0.16.2 tqdm-4.66.1 transformers-4.35.2 triton-2.1.0 typing-inspection-0.4.1 wandb-0.21.0 webdataset-1.0.2 xformers-0.0.23.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: torch-xla 2.4.0\n",
      "Uninstalling torch-xla-2.4.0:\n",
      "  Successfully uninstalled torch-xla-2.4.0\n",
      "\u001b[33mWARNING: Skipping peft as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install torch==2.1.2 torchvision==0.16.2 \"peft>=0.8.2\" matplotlib==3.8.2 \\\n",
    "#      tqdm==4.66.1 einops==0.7.0 xformers requests pillow wandb \\\n",
    "#      bitsandbytes webdataset timm diffusers huggingface_hub accelerate deepspeed scikit-image \\\n",
    "#      -i https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/simple\n",
    "\n",
    "# !pip uninstall torch-xla -y\n",
    "# \"peft>=0.8.2\"\n",
    "\n",
    "# 2025-7-7 installed compatible diffusers huggingface_hub transformers to support torch.compile\n",
    "!pip install torch==2.1.2 torchvision==0.16.2  \\\n",
    "     opencv-python==4.8.1.78 opencv-contrib-python==4.8.1.78 matplotlib==3.8.2 tqdm==4.66.1 einops==0.7.0 \\\n",
    "     xformers requests pillow openexr opencv-python-headless wandb \\\n",
    "     bitsandbytes webdataset timm accelerate deepspeed imageio \\\n",
    "     diffusers==0.25.1 huggingface_hub==0.25.1 transformers==4.35.2 \\\n",
    "     -i https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/simple\n",
    "\n",
    "# 2025-7-7 downgraded diffusers from 0.34.0\n",
    "# diffusers==0.21.4 huggingface-hub==0.16.4 # Install compatible versions that work together\n",
    "# diffusers==0.27.2 Compatible with PyTorch 2.1.2 \n",
    "!pip uninstall torch-xla peft -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc9803fc-6126-4048-9560-f60d429253a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import OpenEXR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0e61069-571b-402f-87fa-b49b50c3bf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: OpenEXR\n",
      "Version: 3.3.4\n",
      "Summary: Python bindings for the OpenEXR image file format\n",
      "Home-page: https://openexr.com\n",
      "Author: \n",
      "Author-email: Contributors to the OpenEXR project <info@openexr.com>\n",
      "License: \n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: numpy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show OpenEXR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efcdb6c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install torch==2.1.2 torchvision==0.16.2 \"peft>=0.8.2\" \\\n",
    "#      opencv-python==4.8.1.78 opencv-contrib-python==4.8.1.78 matplotlib==3.8.2 tqdm==4.66.1 einops==0.7.0 \\\n",
    "#      opencv-python xformers requests pillow openexr opencv-python-headless wandb \\\n",
    "#      bitsandbytes webdataset timm diffusers huggingface_hub accelerate deepspeed \\\n",
    "#      -i https://artifactory.code.bestbuy.com/artifactory/api/pypi/pypi/simple\n",
    "\n",
    "# !pip uninstall torch-xla -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df21cbb0-13cd-4c5a-ab80-660a56415d4b",
   "metadata": {},
   "source": [
    "# check packages versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d571efa-7e9b-49c2-8e8d-0087f7dd2876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate                               1.8.1\n",
      "diffusers                                0.25.1\n",
      "huggingface-hub                          0.25.1\n",
      "OpenEXR                                  3.3.4\n",
      "pyOpenSSL                                25.0.0\n",
      "torch                                    2.1.2\n",
      "torchvision                              0.16.2\n",
      "transformers                             4.35.2\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep \"acc\\|torch\\|diff\\|trans\\|exr\\|Open\\|hug\\|peft\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6707650-1bce-4be4-b97c-ba7347a997a3",
   "metadata": {},
   "source": [
    "# config shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c56498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate more memory for shm\n",
    "!sudo mount -o remount,size=64G /dev/shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8186ccc3-fcc2-4502-aba0-00981bc0d8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         193G   72G  122G  37% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "shm              64G     0   64G   0% /dev/shm\n",
      "/dev/nvme0n2    196G  131G   65G  67% /home/jupyter\n",
      "/dev/nvme0n1p1  193G   72G  122G  37% /usr/local/nvidia/bin\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468e32c-6ee6-429a-8b84-45cf0470fc3d",
   "metadata": {},
   "source": [
    "# check models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e734c9a1-75e2-4d97-b3f9-dafb2e29bd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20K\n",
      "drwxr-xr-x 5 root root 4.0K Jul  6 07:02 models--openai--clip-vit-base-patch32\n",
      "drwxr-xr-x 6 root root 4.0K Jun 28 21:16 models--openai--clip-vit-large-patch14\n",
      "drwxr-xr-x 6 root root 4.0K Jun  9 06:28 models--runwayml--stable-diffusion-v1-5\n",
      "-rw-r--r-- 1 root root    1 Jun  9 06:28 version.txt\n",
      "-rw-r--r-- 1 root root    1 Jun  9 06:28 version_diffusers_cache.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/huggingface/hub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c042516-7876-485c-a5a8-553298ab2d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12K\n",
      "drwxr-xr-x 2 root root 4.0K Jul  6 07:03 blobs\n",
      "drwxr-xr-x 3 root root 4.0K Jul  6 07:02 refs\n",
      "drwxr-xr-x 4 root root 4.0K Jul  6 07:02 snapshots\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05b1585c-9782-4f00-b91b-87a2be1258e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 40 Jul  6 17:17 /home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/refs/main\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/refs/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7f709f2-dbe3-4261-aff7-3748966c4f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/blobs:\n",
      "total 1.2G\n",
      "-rw-r--r-- 1 root root 843K Jul  6 07:02 182766ce89b439768edadda342519f33802f5364\n",
      "-rw-r--r-- 1 root root  592 Jul  6 07:02 4fdaf6842dd5a725b940c92b6b692490ce59d548\n",
      "-rw-r--r-- 1 root root 2.2M Jul  6 07:02 564c0ebd5ce29c4ee4864004aee693deadd3128c\n",
      "-rw-r--r-- 1 root root  316 Jul  6 07:02 5a12a1eb250987a4eee0e3e7d7338c4b22724be1\n",
      "-rw-r--r-- 1 root root 578M Jul  6 07:03 99d28a652e6ec46629ab7047a0ac82c69b1fe11e0ce672c43af65d3a9a3fc05d\n",
      "-rw-r--r-- 1 root root  389 Jul  6 07:02 9bfb42aa97dcd61e89f279ccaee988bccb4fabae\n",
      "-rw-r--r-- 1 root root 4.1K Jul  6 07:02 a2a88b96561196777ca173b15309ea859f4d2ce0\n",
      "-rw-r--r-- 1 root root 578M Jul  6 07:03 a63082132ba4f97a80bea76823f544493bffa8082296d62d71581a4feff1576f\n",
      "-rw-r--r-- 1 root root 513K Jul  6 07:02 bbfec752c9a675946c6dce106def6f35c882dcc2\n"
     ]
    }
   ],
   "source": [
    "!ls -lhR ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/blobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4728c50-f0b6-4fa7-928c-6367b2416971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8.0K\n",
      "drwxr-xr-x 2 root root 4.0K Jul  6 17:34 37000f5cdccec47a3f6f83142bff131370757470\n",
      "drwxr-xr-x 2 root root 4.0K Jul  6 07:03 3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e65f75-4f57-490a-a334-e7013212a10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 581M\n",
      "-rw-r--r-- 1 root root 4.1K Jul  6 07:02 config.json\n",
      "-rw-r--r-- 1 root root 513K Jul  6 07:02 merges.txt\n",
      "-rw-r--r-- 1 root root  316 Jul  6 07:02 preprocessor_config.json\n",
      "-rw-r--r-- 1 root root 578M Jul  6 07:03 pytorch_model.bin\n",
      "-rw-r--r-- 1 root root  389 Jul  6 07:02 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root 2.2M Jul  6 07:02 tokenizer.json\n",
      "-rw-r--r-- 1 root root  592 Jul  6 07:02 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root 843K Jul  6 07:02 vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dfec53e-8c7a-46e7-927f-61688523d75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8.0K\n",
      "-rw-r--r-- 1 root root   40 Jul  6 17:17 main\n",
      "drwxr-xr-x 3 root root 4.0K Jul  6 07:02 refs\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/refs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c50c239b-fa7e-441b-b5f7-63581e131d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 528M\n",
      "-rw-r--r-- 1 root root 528M Jun  9 06:29 vgg16-397923af.pth\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/torch/hub/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e39fe6-9d56-4755-a0b0-0a999f18a8d5",
   "metadata": {},
   "source": [
    "# run training\n",
    "### copied HF/hub and torch.hub from last VM to this VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a0b3de-be24-4ab5-af06-9ad9720cf324",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/.no_exist/32bd64288804d66eefd0ccbe215aa642df71cc41/added_tokens.json...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/.no_exist/32bd64288804d66eefd0ccbe215aa642df71cc41/chat_template.jinja...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/blobs/2c19f6666e0e163c7954df66cb901353fcad088e...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/blobs/4297ea6a8d2bae1fea8f48b45e257814dcb11f69...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/blobs/580c79c6862f31d1f9bd08dd1a415ba0d0502cd9...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/snapshots/32bd64288804d66eefd0ccbe215aa642df71cc41/config.json...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/blobs/702bb12920b291cade3706cf215c1604d2255d93...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/blobs/76e821f1b6f0a9709293c3b6b51ed90980b3166b...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/blobs/9bfb42aa97dcd61e89f279ccaee988bccb4fabae...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/blobs/a2bf730a0c7debf160f7a6b50b3aaf3703e7e88ac73de7a314903141db026dcb...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/snapshots/32bd64288804d66eefd0ccbe215aa642df71cc41/merges.txt...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/refs/main...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/snapshots/32bd64288804d66eefd0ccbe215aa642df71cc41/model.safetensors...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/snapshots/32bd64288804d66eefd0ccbe215aa642df71cc41/special_tokens_map.json...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/snapshots/32bd64288804d66eefd0ccbe215aa642df71cc41/tokenizer.json...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/snapshots/32bd64288804d66eefd0ccbe215aa642df71cc41/tokenizer_config.json...\n",
      "Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/snapshots/32bd64288804d66eefd0ccbe215aa642df71cc41/vocab.json...\n",
      "/ [17/17 files][  3.2 GiB/  3.2 GiB] 100% Done 102.5 MiB/s ETA 00:00:00         \n",
      "Operation completed over 17 objects/3.2 GiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# 2025-5-20 copied hf hub models to gcs and then copied them back to the target\n",
    "# gsutil -m cp -r \\\n",
    "#   ~/.cache/huggingface/hub \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/\n",
    "\n",
    "# on target VM:\n",
    "# mkdir -p ~/.cache/huggingface/hub\n",
    "# gsutil -m cp -r \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/* \\\n",
    "#   ~/.cache/huggingface/hub/\n",
    "\n",
    "# on source vm\n",
    "# copy torch/hub to the gcs and then to target vm\n",
    "# gsutil -m cp -r \\\n",
    "#   ~/.cache/torch/hub \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/torch_hub/\n",
    "\n",
    "# Copying file:///home/jupyter/.cache/torch/hub/checkpoints/vgg16-397923af.pth [Content-Type=application/octet-stream]...\n",
    "# ==> NOTE: You are uploading one or more large file(s), which would run          \n",
    "# significantly faster if you enable parallel composite uploads. This\n",
    "# feature can be enabled by editing the\n",
    "# \"parallel_composite_upload_threshold\" value in your .boto\n",
    "# configuration file. However, note that if you do this large files will\n",
    "# be uploaded as `composite objects\n",
    "# <https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
    "# means that any user who downloads such objects will need to have a\n",
    "# compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
    "# without a compiled crcmod, computing checksums on composite objects is\n",
    "# so slow that gsutil disables downloads of composite objects.\n",
    "\n",
    "# | [1/1 files][527.8 MiB/527.8 MiB] 100% Done                                    \n",
    "# Operation completed over 1 objects/527.8 MiB.  \n",
    "\n",
    "# on target VM:\n",
    "# mkdir -p ~/.cache/torch/hub\n",
    "# gsutil -m cp -r \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/torch_hub/hub/* \\\n",
    "#   ~/.cache/torch/hub/\n",
    "\n",
    "# Copying gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/torch_hub/hub/checkpoints/vgg16-397923af.pth...\n",
    "# - [1/1 files][527.8 MiB/527.8 MiB] 100% Done                                    \n",
    "# Operation completed over 1 objects/527.8 MiB.     \n",
    "\n",
    "# copy all tar raw latent files \n",
    "# on target VM: \n",
    "# mkdir -p ../data/dataspace/polyhaven_tiny\n",
    "# gsutil -m cp -r \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/data/* \\\n",
    "#   ../data/dataspace/polyhaven_tiny\n",
    "\n",
    "# 2025-6-28 copy clip model from gcs\n",
    "# !gsutil -m cp -r \\\n",
    "#   gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/hub/models--openai--clip-vit-large-patch14/ \\\n",
    "#   ~/.cache/huggingface/hub/\n",
    "\n",
    "# 2025-7-5 copy clip model from gs because \"preprocessor_config.json\" is missing in \"gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/models--openai--clip-vit-base-patch32\"\n",
    "# rm -rf ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/\n",
    "# mkdir ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/\n",
    "# gsutil -m cp -r \\\n",
    "#     gs://merlin-on-vertex-ai-test-central/projects/llm/cv/cubediff/hf_hub/models--openai--clip-vit-base-patch32_new/* \\\n",
    "#     ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/\n",
    "# [20/20 files][  2.3 GiB/  2.3 GiB] 100% Done 185.9 MiB/s ETA 00:00:00         \n",
    "# Operation completed over 20 objects/2.3 GiB.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d36b2c-5021-40b4-b2fb-64876f086830",
   "metadata": {},
   "source": [
    "# confirmed 37000f5cdccec47a3f6f83142bff131370757470 should be used for loading CLIPModel from local cache\n",
    "#### copied some missing files (details at test_access_model_personal_2025_7_6.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "230e6b73-a3c3-44c8-8991-0e38c321ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12K\n",
      "drwxr-xr-x 2 root root 4.0K Jul  6 07:03 blobs\n",
      "drwxr-xr-x 3 root root 4.0K Jul  6 07:02 refs\n",
      "drwxr-xr-x 4 root root 4.0K Jul  6 07:02 snapshots\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2003f3b4-b75f-4e39-8f61-795abf669cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/blobs:\n",
      "total 1.2G\n",
      "-rw-r--r-- 1 root root 843K Jul  6 07:02 182766ce89b439768edadda342519f33802f5364\n",
      "-rw-r--r-- 1 root root  592 Jul  6 07:02 4fdaf6842dd5a725b940c92b6b692490ce59d548\n",
      "-rw-r--r-- 1 root root 2.2M Jul  6 07:02 564c0ebd5ce29c4ee4864004aee693deadd3128c\n",
      "-rw-r--r-- 1 root root  316 Jul  6 07:02 5a12a1eb250987a4eee0e3e7d7338c4b22724be1\n",
      "-rw-r--r-- 1 root root 578M Jul  6 07:03 99d28a652e6ec46629ab7047a0ac82c69b1fe11e0ce672c43af65d3a9a3fc05d\n",
      "-rw-r--r-- 1 root root  389 Jul  6 07:02 9bfb42aa97dcd61e89f279ccaee988bccb4fabae\n",
      "-rw-r--r-- 1 root root 4.1K Jul  6 07:02 a2a88b96561196777ca173b15309ea859f4d2ce0\n",
      "-rw-r--r-- 1 root root 578M Jul  6 07:03 a63082132ba4f97a80bea76823f544493bffa8082296d62d71581a4feff1576f\n",
      "-rw-r--r-- 1 root root 513K Jul  6 07:02 bbfec752c9a675946c6dce106def6f35c882dcc2\n"
     ]
    }
   ],
   "source": [
    "!ls -lhR ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/blobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fa628a6-58cf-4137-b4e3-b32f57d50f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8.0K\n",
      "drwxr-xr-x 2 root root 4.0K Jul  6 17:34 37000f5cdccec47a3f6f83142bff131370757470\n",
      "drwxr-xr-x 2 root root 4.0K Jul  6 07:03 3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fae277a-00d9-40ec-8e41-fd142dea671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 581M\n",
      "-rw-r--r-- 1 root root 4.1K Jul  6 07:02 config.json\n",
      "-rw-r--r-- 1 root root 513K Jul  6 07:02 merges.txt\n",
      "-rw-r--r-- 1 root root  316 Jul  6 07:02 preprocessor_config.json\n",
      "-rw-r--r-- 1 root root 578M Jul  6 07:03 pytorch_model.bin\n",
      "-rw-r--r-- 1 root root  389 Jul  6 07:02 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root 2.2M Jul  6 07:02 tokenizer.json\n",
      "-rw-r--r-- 1 root root  592 Jul  6 07:02 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root 843K Jul  6 07:02 vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/3d74acf9a28c67741b2f4f2ea7635f0aaf6f0268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b42a304e-88d0-4bac-abab-a305f2291130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 581M\n",
      "-rw-r--r-- 1 root root 4.1K Jul  6 07:02 config.json\n",
      "-rw-r--r-- 1 root root 513K Jul  6 07:02 merges.txt\n",
      "-rw-r--r-- 1 root root 578M Jul  6 07:03 model.safetensors\n",
      "-rw-r--r-- 1 root root  316 Jul  6 07:02 preprocessor_config.json\n",
      "-rw-r--r-- 1 root root  389 Jul  6 07:02 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root 2.2M Jul  6 07:02 tokenizer.json\n",
      "-rw-r--r-- 1 root root  592 Jul  6 07:02 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root 843K Jul  6 07:02 vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/37000f5cdccec47a3f6f83142bff131370757470"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7675fbc5-0138-437c-bdeb-18d65713a201",
   "metadata": {},
   "source": [
    "## test they can be loaded from local cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b25b423-35b8-4900-b1db-e9770a35730e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPModel, CLIPProcessor\n",
    "\n",
    "# This should now work without network calls\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\", use_safetensors=True, local_files_only=True)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17a05f18-ea71-4d70-b430-04eedd7aeed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(transformers.models.clip.modeling_clip.CLIPModel,\n",
       " transformers.models.clip.processing_clip.CLIPProcessor)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model), type(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "716bf35b-8d9a-40b9-9c8b-e5885d854e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025-5-20 after copying the models, this should work well.\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "# MAX_LEN  = tokenizer.model_max_length\n",
    "# 77"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c963208-3daa-4fd3-a2a4-701be012c782",
   "metadata": {},
   "source": [
    "# test diffusers patch and torch compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27336ce8-22e9-4abb-86ab-b526f8408e91",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Applied comprehensive diffusers patches for torch.compile compatibility\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CLIPProcessor' from 'transformers' (/opt/conda/lib/python3.10/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Now import train_cubediff\u001b[39;00m\n\u001b[1;32m     10\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtrain_cubediff\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Patches imported successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Test compilation\u001b[39;00m\n",
      "File \u001b[0;32m~/mluser/git/llm-cv-pano-cubediff/cl/training/train_cubediff.py:141\u001b[0m\n\u001b[1;32m    137\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTORCH_CUDA_ALLOC_CONF\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_split_size_mb:128\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01margparse\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myaml\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CubeDiffTrainer           \u001b[38;5;66;03m# <- the class you already have\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Add this to train_cubediff.py after importing peft_patch\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpatch_verification\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m verify_patching\n",
      "File \u001b[0;32m~/mluser/git/llm-cv-pano-cubediff/cl/training/trainer.py:55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CLIPProcessor, CLIPModel\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# from peft import get_peft_model, LoraConfig #, prepare_model_for_kbit_training\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwandb\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CLIPProcessor' from 'transformers' (/opt/conda/lib/python3.10/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "# # In a Jupyter cell - UPDATED PATH FIX\n",
    "# import torch\n",
    "# import sys\n",
    "# import os\n",
    "\n",
    "# # Add the PARENT directory to Python path (where 'cl' folder is located)\n",
    "# sys.path.insert(0, '/home/jupyter/mluser/git/llm-cv-pano-cubediff')  # Note: removed '/cl'\n",
    "\n",
    "# # Now import train_cubediff\n",
    "# sys.path.append('/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl')\n",
    "# import train_cubediff\n",
    "\n",
    "# print(\"âœ… Patches imported successfully\")\n",
    "\n",
    "# # Test compilation\n",
    "# print(\"ðŸ§ª Testing torch.compile...\")\n",
    "# dummy_model = torch.nn.Linear(10, 10).cuda()\n",
    "# compiled_model = torch.compile(dummy_model, mode=\"reduce-overhead\")\n",
    "\n",
    "# # Quick test\n",
    "# x = torch.randn(1, 10).cuda()\n",
    "# output = compiled_model(x)\n",
    "\n",
    "# print(\"âœ… torch.compile test passed!\")\n",
    "# print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda7dabc-146a-4240-9aa0-50c43ec6618b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CLIPProcessor' from 'transformers' (/opt/conda/lib/python3.10/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CLIPProcessor, CLIPModel\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CLIPProcessor' from 'transformers' (/opt/conda/lib/python3.10/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "# from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db921943-2d22-4a80-811b-3202e6a9f879",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.53.1\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: peft\n"
     ]
    }
   ],
   "source": [
    "# !pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2093ae6c-0c93-4cfe-b85e-2b0ef8d4e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315deba1-f3d8-4528-a12f-c3cde548b13b",
   "metadata": {},
   "source": [
    "# run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e8545d-310f-4e2f-8204-ef3df3f2d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"/home/jupyter/mluser/git/llm-cv-pano-cubediff\"\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/nvidia/lib64:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "# Set torch compile backend\n",
    "os.environ[\"TORCH_COMPILE_BACKEND\"] = \"inductor\"\n",
    "os.environ[\"ACCELERATE_CONFIG_FILE\"]=\"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/config/accelerate_config.yaml\"\n",
    "os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] =  \"max_split_size_mb:64,expandable_segments:True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ddf3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCELERATE_CONFIG_FILE=\"/home/jupyter/mluser/git/llm-cv-pano-cubediff/cl/config/accelerate_config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56703ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  14%|â–ˆâ–Š           | 1/7 [00:00<00:02,  2.45it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  29%|â–ˆâ–ˆâ–ˆâ–‹         | 2/7 [00:02<00:04,  1.09it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.21it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.25it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.22it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.24it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  14%|â–ˆâ–Š           | 1/7 [00:00<00:01,  4.87it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  14%|â–ˆâ–Š           | 1/7 [00:00<00:01,  4.87it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 3/7 [00:00<00:00, 10.95it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  14%|â–ˆâ–Š           | 1/7 [00:00<00:02,  2.31it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  29%|â–ˆâ–ˆâ–ˆâ–‹         | 2/7 [00:00<00:01,  3.85it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/7 [00:00<00:00,  6.00it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 3/7 [00:02<00:03,  1.23it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6/7 [00:01<00:00,  2.94it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/7 [00:02<00:01,  1.69it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 3/7 [00:02<00:02,  1.38it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.17it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.16it/s]\n",
      "Loading pipeline components...:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/7 [00:02<00:00,  2.70it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.16it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.16it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.16it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.16it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.13it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.13it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.12it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.12it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.10it/s]\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  14%|â–ˆâ–Š           | 1/7 [00:00<00:02,  2.38it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  14%|â–ˆâ–Š           | 1/7 [00:00<00:01,  4.75it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  14%|â–ˆâ–Š           | 1/7 [00:01<00:09,  1.65s/it]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 3/7 [00:02<00:03,  1.20it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/7 [00:02<00:01,  2.03it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6/7 [00:02<00:00,  3.52it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  14%|â–ˆâ–Š           | 1/7 [00:01<00:09,  1.66s/it]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 3/7 [00:01<00:02,  1.72it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.18it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.17it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.13it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.17it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.16it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.14it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.17it/s]\n",
      "Loading pipeline components...:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 3/7 [00:02<00:03,  1.18it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/7 [00:02<00:02,  1.35it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.17it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.16it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.12it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.18it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.17it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.17it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:   0%|                     | 0/7 [00:00<?, ?it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  29%|â–ˆâ–ˆâ–ˆâ–‹         | 2/7 [00:00<00:00,  6.92it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  14%|â–ˆâ–Š           | 1/7 [00:00<00:02,  2.31it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  29%|â–ˆâ–ˆâ–ˆâ–‹         | 2/7 [00:00<00:01,  4.40it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  14%|â–ˆâ–Š           | 1/7 [00:01<00:10,  1.69s/it]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  29%|â–ˆâ–ˆâ–ˆâ–‹         | 2/7 [00:01<00:04,  1.14it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  29%|â–ˆâ–ˆâ–ˆâ–‹         | 2/7 [00:01<00:04,  1.24it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 3/7 [00:01<00:02,  1.85it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6/7 [00:02<00:00,  2.20it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6/7 [00:02<00:00,  1.80it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/7 [00:02<00:01,  1.70it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/7 [00:02<00:01,  1.48it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.16it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.12it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.13it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.14it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.14it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.14it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.14it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.15it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.14it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.16it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.13it/s]\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.12it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:139: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "/opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:139: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "/opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:139: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "/opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:139: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --config_file $ACCELERATE_CONFIG_FILE train_cubediff.py --cfg ../config/tiny_fullrank.yaml > cubediff_log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614229cf-705b-47d4-aa62-b10c9161ae33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e20e0e-4302-4346-aca9-add1872bd433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400da81f-98db-4fa4-9841-5df0946a4c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ebaaa7-5169-40d4-8724-5c69080e368d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
